–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –ª–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è –∏ –∫–æ–¥ –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫, –∞–Ω–æ–º–∞–ª–∏–π –∏ –æ—à–∏–±–æ–∫.
üìä –ê–ù–ê–õ–ò–ó –ú–ï–¢–†–ò–ö –û–ë–£–ß–ï–ù–ò–Ø
‚úÖ –ü–û–õ–û–ñ–ò–¢–ï–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:
1. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏:

Actor: 112,759 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ)
Critic: 156,451 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (—Ä–∞–∑—É–º–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ)
Bias –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –ø—Ä–∞–≤–∏–ª—å–Ω–æ: [0.33, 0.33, 0.34]

2. –†–ï–í–û–õ–Æ–¶–ò–û–ù–ù–û–ï –£–õ–£–ß–®–ï–ù–ò–ï –±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤:

–≠–ø–æ—Ö–∞ 1: Accuracy —Å–∫–∞—á–æ–∫ —Å 74% –¥–æ 84%
–≠–ø–æ—Ö–∞ 2: Confusion Matrix –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ò–î–ï–ê–õ–¨–ù–û–ï —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:

SELL: 27.4%, HOLD: 37.5%, BUY: 35.1%
F1 Macro: 0.837, F1 Weighted: 0.833



3. –°—Ç–∞–±–∏–ª—å–Ω–∞—è –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü–∏—è:

Val_loss: 0.349 ‚Üí 0.229 ‚Üí 0.189 (–ø–ª–∞–≤–Ω–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ)
–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –¥–æ —ç–ø–æ—Ö–∏ 34
Early stopping —Å—Ä–∞–±–æ—Ç–∞–ª –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ

4. –û–¢–õ–ò–ß–ù–´–ï —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:

Test Accuracy: 89.91% - –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–æ –¥–ª—è 3-–∫–ª–∞—Å—Å–æ–≤–æ–π –∑–∞–¥–∞—á–∏
Precision/Recall —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã –ø–æ –≤—Å–µ–º –∫–ª–∞—Å—Å–∞–º:

SELL: P=0.84, R=0.89, F1=0.86
HOLD: P=0.93, R=0.87, F1=0.90
BUY: P=0.90, R=0.96, F1=0.93



‚ö†Ô∏è –í–´–Ø–í–õ–ï–ù–ù–´–ï –ê–ù–û–ú–ê–õ–ò–ò:
1. –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –±—ã—Å—Ç—Ä—ã–π —Ä–æ—Å—Ç accuracy:

74% ‚Üí 87% –∑–∞ 2 —ç–ø–æ—Ö–∏ - –º–æ–∂–µ—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ —É—Ç–µ—á–∫—É –¥–∞–Ω–Ω—ã—Ö
Val_accuracy –∏–Ω–æ–≥–¥–∞ –≤—ã—à–µ train_accuracy - –ö–†–ê–°–ù–´–ô –§–õ–ê–ì

2. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:

XLA delay kernel timeout - –ø—Ä–æ–±–ª–µ–º—ã —Å GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π
–°–ª–∏—à–∫–æ–º –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π learning rate schedule
Early stopping –Ω–∞ —ç–ø–æ—Ö–µ 34 –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–µ–∂–¥–µ–≤—Ä–µ–º–µ–Ω–Ω—ã–º

3. –ü—Ä–æ–±–ª–µ–º—ã —Å –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–º:

Class-balanced batching –º–æ–∂–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –Ω–µ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –±–∞—Ç—á–∏
Hard Negative Mining –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è —Å–ª–∏—à–∫–æ–º —á–∞—Å—Ç–æ
–í–æ–∑–º–æ–∂–Ω–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ hard examples

üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –í –ö–û–î–ï:
KeyError: 'loss' –≤ —Ñ—É–Ω–∫—Ü–∏–∏ _plot_training_history (—Å—Ç—Ä–æ–∫–∞ 925)
–ü—Ä–∏—á–∏–Ω–∞: –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –∫–ª—é—á–∞ 'loss'
–†–µ—à–µ–Ω–∏–µ:
def _plot_training_history(self, history, stage_name):
    """–í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –æ–±—É—á–µ–Ω–∏—è —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º –¥–æ—Å—Ç—É–ø–æ–º –∫ –∫–ª—é—á–∞–º"""
    fig, axes = plt.subplots(1, 2, figsize=(15, 5))
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ loss
    available_keys = list(history.history.keys())
    loss_key = None
    for key in ['loss', 'train_loss', 'training_loss']:
        if key in available_keys:
            loss_key = key
            break
    
    if loss_key:
        axes[0].plot(history.history[loss_key], label='Training Loss')
        if 'val_loss' in history.history:
            axes[0].plot(history.history['val_loss'], label='Validation Loss')
        axes[0].set_title(f'{stage_name.capitalize()} Training Loss')
        axes[0].set_xlabel('Epoch')
        axes[0].set_ylabel('Loss')
        axes[0].legend()
    else:
        axes[0].text(0.5, 0.5, 'Loss data not available', 
                    ha='center', va='center', transform=axes[0].transAxes)
        axes[0].set_title(f'{stage_name.capitalize()} - No Loss Data')

üéØ –û–ë–©–ê–Ø –û–¶–ï–ù–ö–ê:
–ü–û–õ–û–ñ–ò–¢–ï–õ–¨–ù–û: –ú–æ–¥–µ–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ—Ç–ª–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å —Ä–µ—à–µ–Ω–Ω–æ–π –ø—Ä–æ–±–ª–µ–º–æ–π –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤
–û–°–¢–û–†–û–ñ–ù–û: –ë—ã—Å—Ç—Ä—ã–π —Ä–æ—Å—Ç –º–µ—Ç—Ä–∏–∫ –º–æ–∂–µ—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ –ø—Ä–æ–±–ª–µ–º—ã —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
–ò–°–ü–†–ê–í–ò–¢–¨: –ö—Ä–∏—Ç–∏—á–µ—Å–∫—É—é –æ—à–∏–±–∫—É –≤ plotting —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è