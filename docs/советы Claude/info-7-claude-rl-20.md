import tensorflow as tf
import numpy as np

class AntiOverfittingCallback(tf.keras.callbacks.Callback):
    """
    –ö–æ–ª–±—ç–∫ –¥–ª—è –±–æ—Ä—å–±—ã —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º
    """
    def __init__(self, patience=5, min_improvement=0.01):
        super().__init__()
        self.patience = patience
        self.min_improvement = min_improvement
        self.wait = 0
        self.best_val_loss = np.inf
        
    def on_epoch_end(self, epoch, logs=None):
        val_loss = logs.get('val_loss')
        train_loss = logs.get('loss')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
        overfitting_ratio = val_loss / train_loss if train_loss > 0 else 1.0
        
        if overfitting_ratio > 1.3:  # –ï—Å–ª–∏ val_loss > train_loss * 1.3
            print(f"\n‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ —ç–ø–æ—Ö–µ {epoch+1}!")
            print(f"   Val_loss/


–§–∞–π–ª 7: –ù–æ–≤—ã–π —Ñ–∞–π–ª regularization_callback.py
–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π —Ñ–∞–π–ª:
import tensorflow as tf
import numpy as np

class AntiOverfittingCallback(tf.keras.callbacks.Callback):
    """
    –ö–æ–ª–±—ç–∫ –¥–ª—è –±–æ—Ä—å–±—ã —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º
    """
    def __init__(self, patience=5, min_improvement=0.01):
        super().__init__()
        self.patience = patience
        self.min_improvement = min_improvement
        self.wait = 0
        self.best_val_loss = np.inf
        
    def on_epoch_end(self, epoch, logs=None):
        val_loss = logs.get('val_loss')
        train_loss = logs.get('loss')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
        overfitting_ratio = val_loss / train_loss if train_loss > 0 else 1.0
        
        if overfitting_ratio > 1.3:  # –ï—Å–ª–∏ val_loss > train_loss * 1.3
            print(f"\n‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ —ç–ø–æ—Ö–µ {epoch+1}!")
            print(f"   Val_loss/Train_loss = {overfitting_ratio:.2f}")
            
            # –£–º–µ–Ω—å—à–∞–µ–º learning rate
            current_lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))
            new_lr = current_lr * 0.8
            tf.keras.backend.set_value(self.model.optimizer.learning_rate, new_lr)
            print(f"   –°–Ω–∏–∂–∞–µ–º LR: {current_lr:.2e} -> {new_lr:.2e}")
        
        # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º —É–ª—É—á—à–µ–Ω–∏–µ val_loss
        if val_loss < self.best_val_loss - self.min_improvement:
            self.best_val_loss = val_loss
            self.wait = 0
        else:
            self.wait += 1
            
        if self.wait >= self.patience and epoch > 20:  # –ú–∏–Ω–∏–º—É–º 20 —ç–ø–æ—Ö
            print(f"\nüõë –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ: –Ω–µ—Ç —É–ª—É—á—à–µ–Ω–∏–π {self.patience} —ç–ø–æ—Ö")
            self.model.stop_training = True

–§–∞–π–ª 8: train_model.py
–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ: –î–æ–±–∞–≤–∏—Ç—å –∏–º–ø–æ—Ä—Ç –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∫–æ–ª–±—ç–∫–∞ (—Å—Ç—Ä–æ–∫–∞ ~20)
–î–û–ë–ê–í–ò–¢–¨ –í –ò–ú–ü–û–†–¢–´:
# –î–û–ë–ê–í–ò–¢–¨ –í –ò–ú–ü–û–†–¢–´
from regularization_callback import AntiOverfittingCallback

–í —Ñ—É–Ω–∫—Ü–∏–∏ train_xlstm_rl_system, –≤ –±–ª–æ–∫–µ callbacks (—Å—Ç—Ä–æ–∫–∞ ~400):
–ó–ê–ú–ï–ù–ò–¢–¨:
# –°–¢–ê–†–´–ô –ö–û–î
callbacks = [
    tf.keras.callbacks.EarlyStopping(...),
    MemoryCleanupCallback(),
    DetailedProgressCallback(),
    tf.keras.callbacks.ReduceLROnPlateau(...)
]

–ù–ê –ù–û–í–´–ô –ö–û–î:
# –ù–û–í–´–ô –ö–û–î –° –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ú–ò –ö–û–õ–ë–≠–ö–ê–ú–ò
callbacks = [
    tf.keras.callbacks.EarlyStopping(
        monitor='val_loss',
        mode='min',
        patience=15,
        restore_best_weights=True,
        verbose=1,
        min_delta=0.001
    ),
    AntiOverfittingCallback(patience=8, min_improvement=0.005),  # –ù–û–í–´–ô –ö–û–õ–ë–≠–ö
    MemoryCleanupCallback(),
    DetailedProgressCallback(),
    tf.keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.7,
        patience=8,
        min_lr=1e-6,
        verbose=1
    )
]

–§–∞–π–ª 9: models/xlstm_rl_model.py
–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ: –ú–µ—Ç–æ–¥ build_model, –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ Dropout (—Å—Ç—Ä–æ–∫–∞ ~80)
–ù–ê–ô–¢–ò –±–ª–æ–∫:
# –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ —Å–ª–æ–∏
dense1 = Dense(64, activation='relu', kernel_regularizer=l2(0.001), name='dense_1')(xlstm_final)
dropout1 = Dropout(0.4)(dense1)

dense2 = Dense(32, activation='relu', kernel_regularizer=l2(0.001), name='dense_2')(dropout1)
dropout2 = Dropout(0.3)(dense2)

–ó–ê–ú–ï–ù–ò–¢–¨ –ù–ê:
# –£–°–ò–õ–ï–ù–ù–ê–Ø –†–ï–ì–£–õ–Ø–†–ò–ó–ê–¶–ò–Ø
dense1 = Dense(64, activation='relu', kernel_regularizer=l2(0.002), name='dense_1')(xlstm_final)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º L2
dropout1 = Dropout(0.5)(dense1)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º dropout —Å 0.4 –¥–æ 0.5

dense2 = Dense(32, activation='relu', kernel_regularizer=l2(0.002), name='dense_2')(dropout1)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º L2
dropout2 = Dropout(0.4)(dense2)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º dropout —Å 0.3 –¥–æ 0.4

# –î–û–ë–ê–í–õ–Ø–ï–ú –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ô –°–õ–û–ô –î–õ–Ø –õ–£–ß–®–ï–ô –†–ï–ì–£–õ–Ø–†–ò–ó–ê–¶–ò–ò
dense3 = Dense(16, activation='relu', kernel_regularizer=l2(0.001), name='dense_3')(dropout2)
dropout3 = Dropout(0.3)(dense3)

–ò –ò–ó–ú–ï–ù–ò–¢–¨ –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π:
# –°–¢–ê–†–´–ô –ö–û–î
outputs = Dense(3, activation='softmax', name='output_layer')(dropout2)

–ù–ê:
# –ù–û–í–´–ô –ö–û–î
outputs = Dense(3, activation='softmax', name='output_layer')(dropout3)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º dropout3

–§–∞–π–ª 10: train_model.py
–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ (—Å—Ç—Ä–æ–∫–∞ ~450)
–ó–ê–ú–ï–ù–ò–¢–¨:
# –°–¢–ê–†–´–ô –ö–û–î
optimizer = tf.keras.optimizers.Adam(
    learning_rate=0.001,
    clipnorm=1.0
)

–ù–ê –ù–û–í–´–ô –ö–û–î:
# –ù–û–í–´–ô –ö–û–î - –ë–û–õ–ï–ï –ö–û–ù–°–ï–†–í–ê–¢–ò–í–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò
optimizer = tf.keras.optimizers.Adam(
    learning_rate=0.0005,  # –£–º–µ–Ω—å—à–∞–µ–º LR —Å 0.001 –¥–æ 0.0005
    clipnorm=0.5,          # –£–º–µ–Ω—å—à–∞–µ–º clipnorm —Å 1.0 –¥–æ 0.5
    weight_decay=0.0001    # –î–æ–±–∞–≤–ª—è–µ–º weight decay
)

–§–∞–π–ª 11: train_model.py
–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ batch_size (—Å—Ç—Ä–æ–∫–∞ ~480)
–ó–ê–ú–ï–ù–ò–¢–¨:
# –°–¢–ê–†–´–ô –ö–û–î
history = xlstm_model.train(
    X_train_to_model, y_train,
    X_val_to_model, y_val,
    epochs=100,
    batch_size=16,  # –°—Ç–∞—Ä—ã–π —Ä–∞–∑–º–µ—Ä
    class_weight=class_weight_dict,
    custom_callbacks=callbacks
)

–ù–ê –ù–û–í–´–ô –ö–û–î:
# –ù–û–í–´–ô –ö–û–î - –£–í–ï–õ–ò–ß–ò–í–ê–ï–ú BATCH SIZE –î–õ–Ø –°–¢–ê–ë–ò–õ–¨–ù–û–°–¢–ò
history = xlstm_model.train(
    X_train_to_model, y_train,
    X_val_to_model, y_val,
    epochs=80,      # –£–º–µ–Ω—å—à–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö —Å 100 –¥–æ 80
    batch_size=32,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º batch_size —Å 16 –¥–æ 32
    class_weight=class_weight_dict,
    custom_callbacks=callbacks
)

–§–∞–π–ª 12: –ù–æ–≤—ã–π —Ñ–∞–π–ª validation_metrics.py
–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π —Ñ–∞–π–ª –¥–ª—è –ª—É—á—à–µ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞:
import tensorflow as tf
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

class ValidationMetricsCallback(tf.keras.callbacks.Callback):
    """
    –î–µ—Ç–∞–ª—å–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –º–µ—Ç—Ä–∏–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    """
    def __init__(self, X_val, y_val, class_names=['BUY', 'SELL', 'HOLD']):
        super().__init__()
        self.X_val = X_val
        self.y_val = y_val
        self.class_names = class_names
        
    def on_epoch_end(self, epoch, logs=None):
        if epoch % 5 == 0:  # –ö–∞–∂–¥—ã–µ 5 —ç–ø–æ—Ö
            y_pred = self.model.predict(self.X_val, verbose=0)
            y_pred_classes = np.argmax(y_pred, axis=1)
            y_true_classes = np.argmax(self.y_val, axis=1)
            
            print(f"\nüìä –î–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —ç–ø–æ—Ö–µ {epoch+1}:")
            
            # Confusion Matrix
            cm = confusion_matrix(y_true_classes, y_pred_classes)
            print("Confusion Matrix:")
            print("     BUY  SELL HOLD")
            for i, row in enumerate(cm):
                print(f"{self.class_names[i]:4s} {row}")
            
            # Classification Report
            report = classification_report(
                y_true_classes, y_pred_classes, 
                target_names=self.class_names,
                output_dict=True
            )
            
            print(f"Macro Avg F1-Score: {report['macro avg']['f1-score']:.3f}")
            print(f"Weighted Avg F1-Score: {report['weighted avg']['f1-score']:.3f}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–∏—Å–±–∞–ª–∞–Ω—Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            pred_distribution = np.bincount(y_pred_classes) / len(y_pred_classes)
            print(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: BUY={pred_distribution[0]:.1%}, SELL={pred_distribution[1]:.1%}, HOLD={pred_distribution[2]:.1%}")

–§–∞–π–ª 13: train_model.py
–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π –∫–æ–ª–±—ç–∫ –≤ —Å–ø–∏—Å–æ–∫ (–ø–æ—Å–ª–µ –∏–º–ø–æ—Ä—Ç–∞ ValidationMetricsCallback):
# –î–û–ë–ê–í–ò–¢–¨ –í –ò–ú–ü–û–†–¢–´
from validation_metrics import ValidationMetricsCallback

# –í –±–ª–æ–∫–µ callbacks –¥–æ–±–∞–≤–∏—Ç—å:
callbacks = [
    # ... —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∫–æ–ª–±—ç–∫–∏ ...
    ValidationMetricsCallback(X_val_to_model, y_val),  # –ù–û–í–´–ô –ö–û–õ–ë–≠–ö
]

–†–µ–∑—é–º–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π:

–£–≤–µ–ª–∏—á–∏–ª–∏ –ø–æ—Ä–æ–≥–∏ –¥–ª—è BUY/SELL - —Ç–µ–ø–µ—Ä—å –Ω—É–∂–Ω—ã –±–æ–ª–µ–µ —Å–∏–ª—å–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã
–ò—Å–ø—Ä–∞–≤–∏–ª–∏ –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ - —É–º–µ–Ω—å—à–∏–ª–∏ –≤–µ—Å–∞ BUY/SELL, —É–≤–µ–ª–∏—á–∏–ª–∏ –≤–µ—Å HOLD
–£–ª—É—á—à–∏–ª–∏ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é - –±–æ–ª—å—à–µ dropout, L2, –º–µ–Ω—å—à–µ LR
–î–æ–±–∞–≤–∏–ª–∏ –∑–∞—â–∏—Ç—É –æ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è - –Ω–æ–≤—ã–µ –∫–æ–ª–±—ç–∫–∏
–ò—Å–ø—Ä–∞–≤–∏–ª–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ - –±–æ–ª—å—à–µ HOLD, –º–µ–Ω—å—à–µ —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
–î–æ–±–∞–≤–∏–ª–∏ –¥–µ—Ç–∞–ª—å–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ - –ª—É—á—à–µ –≤–∏–¥–∏–º —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç

–≠—Ç–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–æ–ª–∂–Ω—ã —Ä–µ—à–∏—Ç—å –æ—Å–Ω–æ–≤–Ω—É—é –ø—Ä–æ–±–ª–µ–º—É: –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç —á–∞—â–µ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å HOLD (—É–≤–µ–ª–∏—á–∏—Ç—Å—è recall –¥–ª—è HOLD) –∏ –±—É–¥–µ—Ç –º–µ–Ω–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–π —Å —Ç–æ—Ä–≥–æ–≤—ã–º–∏ —Å–∏–≥–Ω–∞–ª–∞–º–∏, —á—Ç–æ —É–ª—É—á—à–∏—Ç –æ–±—â—É—é —Ç–æ—á–Ω–æ—Å—Ç—å.