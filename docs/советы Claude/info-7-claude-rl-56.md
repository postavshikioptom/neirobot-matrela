–ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å:
–ù—É–∂–Ω–æ —è–≤–Ω–æ —É–∫–∞–∑–∞—Ç—å labels (—Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤) –≤ –≤—ã–∑–æ–≤–µ classification_report –∏ confusion_matrix. –≠—Ç–æ –∑–∞—Å—Ç–∞–≤–∏—Ç sklearn —É—á–∏—Ç—ã–≤–∞—Ç—å –≤—Å–µ 3 –∫–ª–∞—Å—Å–∞, –¥–∞–∂–µ –µ—Å–ª–∏ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –∏–∑ –Ω–∏—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ —Ç–µ–∫—É—â–µ–π –≤—ã–±–æ—Ä–∫–µ.
–§–∞–π–ª, –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å: validation_metrics_callback.py
–í–æ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–¥ –¥–ª—è validation_metrics_callback.py:
import tensorflow as tf
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np
# import logging # üî• –£–î–ê–õ–ï–ù–û: –ò–º–ø–æ—Ä—Ç logging

# üî• –£–î–ê–õ–ï–ù–û: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–≥–≥–µ—Ä–∞
# logger = logging.getLogger('validation_callback')

class ValidationMetricsCallback(tf.keras.callbacks.Callback):
    """
    –î–µ—Ç–∞–ª—å–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –º–µ—Ç—Ä–∏–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–ª—è Supervised Pre-training (–≠—Ç–∞–ø 1)
    """
    def __init__(self, X_val, y_val, class_names=['SELL', 'HOLD', 'BUY']):
        super().__init__()
        self.X_val = X_val
        self.y_val = y_val
        self.class_names = class_names
        # üî• –î–û–ë–ê–í–õ–ï–ù–û: –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –º–µ—Ç–∫–∏ (0, 1, 2)
        self.all_labels = [0, 1, 2] 
        
    def on_epoch_end(self, epoch, logs=None):
        if (epoch + 1) % 5 == 0:  # –ö–∞–∂–¥—ã–µ 5 —ç–ø–æ—Ö
            # üî• –ò–ó–ú–ï–ù–ï–ù–û: logger.info -> print
            print(f"\nüìä –î–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —ç–ø–æ—Ö–µ {epoch+1}:")
            
            y_pred_probs = self.model.predict(self.X_val, verbose=0)
            y_pred_classes = np.argmax(y_pred_probs, axis=1)
            
            if self.y_val.ndim > 1 and self.y_val.shape[1] > 1:
                y_true_classes = np.argmax(self.y_val, axis=1)
            else:
                y_true_classes = self.y_val
            
            # Confusion Matrix
            # üî• –ò–ó–ú–ï–ù–ï–ù–û: –î–æ–±–∞–≤–ª–µ–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä 'labels=self.all_labels'
            cm = confusion_matrix(y_true_classes, y_pred_classes, labels=self.all_labels) 
            # üî• –ò–ó–ú–ï–ù–ï–ù–û: logger.info -> print
            print("Confusion Matrix:")
            
            header = "     " + " ".join([f"{name:4s}" for name in self.class_names])
            # üî• –ò–ó–ú–ï–ù–ï–ù–û: logger.info -> print
            print(header)
            for i, row in enumerate(cm):
                row_str = " ".join([f"{val:4d}" for val in row])
                # üî• –ò–ó–ú–ï–ù–ï–ù–û: logger.info -> print
                print(f"{self.class_names[i]:4s} {row_str}")
            
            # Classification Report
            # üî• –ò–ó–ú–ï–ù–ï–ù–û: –î–æ–±–∞–≤–ª–µ–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä 'labels=self.all_labels'
            report_dict = classification_report(
                y_true_classes, y_pred_classes, 
                target_names=self.class_names,
                labels=self.all_labels, # üî• –î–û–ë–ê–í–õ–ï–ù–û
                output_dict=True,
                zero_division=0 
            )
            
            # üî• –ò–ó–ú–ï–ù–ï–ù–û: logger.info -> print
            print(f"Macro Avg F1-Score: {report_dict['macro avg']['f1-score']:.3f}")
            # üî• –ò–ó–ú–ï–ù–ï–ù–û: logger.info -> print
            print(f"Weighted Avg F1-Score: {report_dict['weighted avg']['f1-score']:.3f}")
            
            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            pred_distribution = np.bincount(y_pred_classes, minlength=len(self.class_names)) / len(y_pred_classes)
            pred_dist_str = ", ".join([f"{name}={dist:.1%}" for name, dist in zip(self.class_names, pred_distribution)])
            # üî• –ò–ó–ú–ï–ù–ï–ù–û: logger.info -> print
            print(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {pred_dist_str}")



–§–∞–π–ª, –∫–æ—Ç–æ—Ä—ã–π —Ç–∞–∫–∂–µ –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å: train_model.py
–•–æ—Ç—è –æ—à–∏–±–∫–∞ –≤–æ–∑–Ω–∏–∫–ª–∞ –≤ –∫–æ–ª–ª–±—ç–∫–µ, –∞–Ω–∞–ª–æ–≥–∏—á–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞ –º–æ–∂–µ—Ç –≤–æ–∑–Ω–∏–∫–Ω—É—Ç—å –∏ –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–µ –≤ train_model.py. –ù—É–∂–Ω–æ –ø—Ä–∏–º–µ–Ω–∏—Ç—å —Ç–æ –∂–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ.
–í–æ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –∫–æ–¥–∞ –¥–ª—è train_model.py (—Ç–æ–ª—å–∫–æ —Ç–µ —á–∞—Å—Ç–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–µ–Ω—è—é—Ç—Å—è):
# ... (–æ—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥) ...

    def stage1_supervised_pretraining(self):
        """–≠–¢–ê–ü 1: Supervised Pre-training"""
        print("=== –≠–¢–ê–ü 1: SUPERVISED PRE-TRAINING ===")
        
        self.model.compile_for_supervised_learning()
        
        callbacks = [
            tf.keras.callbacks.EarlyStopping(
                patience=10, restore_best_weights=True, monitor='val_accuracy'
            ),
            tf.keras.callbacks.ReduceLROnPlateau(
                factor=0.5, patience=5, monitor='val_loss'
            ),
            tf.keras.callbacks.ModelCheckpoint(
                'models/best_supervised_model.keras', 
                save_best_only=True, monitor='val_accuracy'
            ),
            ValidationMetricsCallback(self.X_val, self.y_val)
        ]
        
        print(f"–ù–∞—á–∏–Ω–∞–µ–º supervised –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ {config.SUPERVISED_EPOCHS} —ç–ø–æ—Ö...")
        
        history = self.model.actor_model.fit(
            self.X_train, self.y_train,
            validation_data=(self.X_val, self.y_val),
            epochs=config.SUPERVISED_EPOCHS,
            batch_size=config.SUPERVISED_BATCH_SIZE,
            callbacks=callbacks,
            verbose=1
        )
        
        print("=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ SUPERVISED –û–ë–£–ß–ï–ù–ò–Ø ===")
        
        y_pred_probs = self.model.actor_model.predict(self.X_test, verbose=0)
        y_pred = np.argmax(y_pred_probs, axis=1)
        
        accuracy = accuracy_score(self.y_test, y_pred)
        print(f"–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ: {accuracy:.4f}")
        
        class_names = ['SELL', 'HOLD', 'BUY']
        # üî• –ò–ó–ú–ï–ù–ï–ù–û: –î–æ–±–∞–≤–ª–µ–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä 'labels=[0, 1, 2]'
        report = classification_report(self.y_test, y_pred, target_names=class_names, labels=[0, 1, 2], zero_division=0) 
        print(f"–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç:\n{report}")
        
        # üî• –ò–ó–ú–ï–ù–ï–ù–û: –î–æ–±–∞–≤–ª–µ–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä 'labels=[0, 1, 2]'
        cm = confusion_matrix(self.y_test, y_pred, labels=[0, 1, 2])
        print(f"–ú–∞—Ç—Ä–∏—Ü–∞ –ø—É—Ç–∞–Ω–∏—Ü—ã:\n{cm}")
        
        pred_dist = np.bincount(y_pred, minlength=3)
        total_pred = len(y_pred)
        print(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:")
        print(f"SELL: {pred_dist[0]} ({pred_dist[0]/total_pred:.2%})")
        print(f"HOLD: {pred_dist[1]} ({pred_dist[1]/total_pred:.2%})")
        print(f"BUY: {pred_dist[2]} ({pred_dist[2]/total_pred:.2%})")
        
        self.model.save(stage="_supervised")
        self.model.is_supervised_trained = True
        
        self._plot_training_history(history, "supervised")
        
        return {
            'accuracy': accuracy,
            'classification_report': report,
            'confusion_matrix': cm,
            'history': history.history
        }

# ... (–æ—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥) ...

–û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π:

labels=self.all_labels (–≤ –∫–æ–ª–ª–±—ç–∫–µ) / labels=[0, 1, 2] (–≤ train_model.py): –ú—ã —è–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º sklearn, —á—Ç–æ —É –Ω–∞—Å –µ—Å—Ç—å 3 –∫–ª–∞—Å—Å–∞ (—Å –º–µ—Ç–∫–∞–º–∏ 0, 1, 2), –¥–∞–∂–µ –µ—Å–ª–∏ –≤ —Ç–µ–∫—É—â–µ–π –≤—ã–±–æ—Ä–∫–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø—Ä–∏–º–µ—Ä—ã –∫–∞–∫–æ–≥–æ-–ª–∏–±–æ –∫–ª–∞—Å—Å–∞. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç classification_report –∏ confusion_matrix –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Å—Ç—Ä–æ–∏—Ç—å –æ—Ç—á–µ—Ç—ã, –≤–∫–ª—é—á–∞—è —Å—Ç—Ä–æ–∫–∏ –∏ —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –∫–ª–∞—Å—Å–æ–≤ (–∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –∏–º–µ—Ç—å –Ω—É–ª–∏).

–≠—Ç–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–æ–ª–∂–Ω—ã –ø–æ–ª–Ω–æ—Å—Ç—å—é —É—Å—Ç—Ä–∞–Ω–∏—Ç—å ValueError –∏ –æ–±–µ—Å–ø–µ—á–∏—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –≤—Å–µ—Ö 3 –∫–ª–∞—Å—Å–æ–≤.