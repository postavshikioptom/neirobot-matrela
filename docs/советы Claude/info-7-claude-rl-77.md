
–ù–∞–º –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –º–µ–Ω–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–º –≤ —Å—Ç–æ—Ä–æ–Ω—É —Å–Ω–∏–∂–µ–Ω–∏—è.
–ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ feature_engineering.py (–º–µ—Ç–æ–¥ calculate_adaptive_threshold)
def calculate_adaptive_threshold(self, df, base_threshold=0.005):
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ —Ä—ã–Ω–∫–∞
    ... (—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥) ...
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º ATR –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω—ã
    last_price = df['close'].iloc[-1]
    if last_price > 0:
        normalized_atr = atr / last_price
    else:
        normalized_atr = 0.001
    
    # üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –ë–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –º–Ω–æ–∂–∏—Ç–µ–ª—è –¥–ª—è –Ω–∏–∑–∫–æ–≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã—Ö –∞–∫—Ç–∏–≤–æ–≤
    # –£–º–µ–Ω—å—à–∞–µ–º –º–Ω–æ–∂–∏—Ç–µ–ª—å, —á—Ç–æ–±—ã –Ω–µ –¥–µ–ª–∞—Ç—å –ø–æ—Ä–æ–≥ —Å–ª–∏—à–∫–æ–º —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–º
    atr_multiplier = config.ADAPTIVE_THRESHOLD_MULTIPLIER
    # –ï—Å–ª–∏ normalized_atr –æ—á–µ–Ω—å –Ω–∏–∑–∫–∏–π, –º—ã –º–æ–∂–µ–º –Ω–µ–º–Ω–æ–≥–æ —É–≤–µ–ª–∏—á–∏—Ç—å –º–Ω–æ–∂–∏—Ç–µ–ª—å,
    # –Ω–æ –Ω–µ —Ç–∞–∫ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ, –∫–∞–∫ —Ä–∞–Ω—å—à–µ, —á—Ç–æ–±—ã –Ω–µ –ø–æ–ª—É—á–∏—Ç—å —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ BUY/SELL
    if normalized_atr < 0.0005:  # –ï—Å–ª–∏ ATR –º–µ–Ω—å—à–µ 0.05%
        atr_multiplier = 0.9   # –ù–µ–º–Ω–æ–≥–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –º–Ω–æ–∂–∏—Ç–µ–ª—å
    elif normalized_atr < 0.001: # –ï—Å–ª–∏ ATR –º–µ–Ω—å—à–µ 0.1%
        atr_multiplier = 0.8
        
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
    # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ 0.05% (0.0005), –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π 1% (0.01)
    adaptive_threshold = max(0.0005, min(0.01, normalized_atr * atr_multiplier))
    
    # üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –£–±–∏—Ä–∞–µ–º –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞,
    # —Ç–∞–∫ –∫–∞–∫ —Ç–µ–ø–µ—Ä—å –º—ã —Ö–æ—Ç–∏–º –µ–≥–æ –Ω–µ–º–Ω–æ–≥–æ —É–≤–µ–ª–∏—á–∏—Ç—å –¥–ª—è HOLD
    # recommended_threshold_from_log = self._get_recommended_threshold_from_data(df, future_window=config.FUTURE_WINDOW)
    # if recommended_threshold_from_log is not None and recommended_threshold_from_log < adaptive_threshold * 0.5:
    #     print(f"–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Å–Ω–∏–∂–∞–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–æ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω–æ–≥–æ: {recommended_threshold_from_log:.6f}")
    #     adaptive_threshold = recommended_threshold_from_log
        
    print(f"[ADAPTIVE] Base threshold: {base_threshold:.6f}, ATR: {normalized_atr:.6f}, "
          f"Adaptive threshold: {adaptive_threshold:.6f}")
    
    return adaptive_threshold

–ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ config.py:
# –ë—ã–ª–æ:
# ADAPTIVE_THRESHOLD_MIN = 0.0001  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ (0.01%)
# ADAPTIVE_THRESHOLD_MAX = 0.02    # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ (2%)

# –ò–∑–º–µ–Ω–∏—Ç–µ –Ω–∞:
ADAPTIVE_THRESHOLD_MIN = 0.0005  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ (0.05%) - –Ω–µ–º–Ω–æ–≥–æ –ø–æ–≤—ã—à–∞–µ–º
ADAPTIVE_THRESHOLD_MAX = 0.01    # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ (1%) - –Ω–µ–º–Ω–æ–≥–æ –ø–æ–Ω–∏–∂–∞–µ–º
ADAPTIVE_THRESHOLD_MULTIPLIER = 0.7 # –í–µ—Ä–Ω—É—Ç—å –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É –∑–Ω–∞—á–µ–Ω–∏—é –∏–ª–∏ –Ω–µ–º–Ω–æ–≥–æ —É–º–µ–Ω—å—à–∏—Ç—å

–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—à–∏–±–∫–∏ AttributeError: 'str' object has no attribute 'name'
–≠—Ç–∞ –æ—à–∏–±–∫–∞ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ CosineDecayCallback, –∫–æ–≥–¥–∞ –æ–Ω –ø—ã—Ç–∞–µ—Ç—Å—è –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ self.model.optimizer.learning_rate. –ü—Ä–æ–±–ª–µ–º–∞ –≤ —Ç–æ–º, —á—Ç–æ self.model.optimizer –≤ —ç—Ç–æ—Ç –º–æ–º–µ–Ω—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π (–Ω–∞–∑–≤–∞–Ω–∏–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞), –∞ –Ω–µ –æ–±—ä–µ–∫—Ç–æ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞.
–ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ —Ñ–∞–π–ª–µ train_model.py (–≤ –∫–ª–∞—Å—Å–µ CosineDecayCallback)
class CosineDecayCallback(tf.keras.callbacks.Callback):
    """–ö–∞—Å—Ç–æ–º–Ω—ã–π Cosine Decay callback –¥–ª—è TensorFlow 2.19.0"""
    def __init__(self, initial_learning_rate, decay_steps, alpha=0.0):
        super().__init__()
        self.initial_learning_rate = initial_learning_rate
        self.decay_steps = decay_steps
        self.alpha = alpha
    
    def on_epoch_begin(self, epoch, logs=None):
        if epoch < self.decay_steps:
            cosine_decay = 0.5 * (1 + math.cos(math.pi * epoch / self.decay_steps))
            decayed_learning_rate = (self.initial_learning_rate - self.alpha) * cosine_decay + self.alpha
            
            # üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ self.model.optimizer —è–≤–ª—è–µ—Ç—Å—è –æ–±—ä–µ–∫—Ç–æ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
            if hasattr(self.model, 'optimizer') and hasattr(self.model.optimizer, 'learning_rate'):
                tf.keras.backend.set_value(self.model.optimizer.learning_rate, decayed_learning_rate)
            else:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞: –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ –∏–º–µ–µ—Ç –∞—Ç—Ä–∏–±—É—Ç–∞ 'learning_rate' –Ω–∞ —ç–ø–æ—Ö–µ {epoch}")
                # –ï—Å–ª–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω, –º–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –ø–æ–ª—É—á–∏—Ç—å –µ–≥–æ –∏–∑ logs –∏–ª–∏ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å
                # (–≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–æ–≥–æ, –∫–∞–∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è self.model.optimizer)


===========
–í–æ—Ç –∫–∞–∫ –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å –∫–æ–¥ –≤ —Ñ–∞–π–ª–µ train_model.py (–≤ –∫–ª–∞—Å—Å–µ CosineDecayCallback):
class CosineDecayCallback(tf.keras.callbacks.Callback):
    """–ö–∞—Å—Ç–æ–º–Ω—ã–π Cosine Decay callback –¥–ª—è TensorFlow 2.19.0"""
    def __init__(self, initial_learning_rate, decay_steps, alpha=0.0):
        super().__init__()
        self.initial_learning_rate = initial_learning_rate
        self.decay_steps = decay_steps
        self.alpha = alpha
        # üî• –î–û–ë–ê–í–õ–ï–ù–û: –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –ø–æ—Å–ª–µ –∫–æ–º–ø–∏–ª—è—Ü–∏–∏
        self.optimizer_ref = None 
    
    def on_train_begin(self, logs=None):
        # üî• –î–û–ë–ê–í–õ–ï–ù–û: –ü–æ–ª—É—á–∞–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –ø–æ—Å–ª–µ –Ω–∞—á–∞–ª–∞ –æ–±—É—á–µ–Ω–∏—è
        # self.model - —ç—Ç–æ —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è Keras –º–æ–¥–µ–ª—å (actor_model –≤ –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ)
        if hasattr(self.model, 'optimizer') and hasattr(self.model.optimizer, 'learning_rate'):
            self.optimizer_ref = self.model.optimizer
        else:
            print("‚ö†Ô∏è –û—à–∏–±–∫–∞: –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ –∏–º–µ–µ—Ç –∞—Ç—Ä–∏–±—É—Ç–∞ 'learning_rate' –≤ on_train_begin.")

    def on_epoch_begin(self, epoch, logs=None):
        if self.optimizer_ref is None:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞: –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è CosineDecayCallback –Ω–∞ —ç–ø–æ—Ö–µ {epoch}.")
            return

        if epoch < self.decay_steps:
            cosine_decay = 0.5 * (1 + math.cos(math.pi * epoch / self.decay_steps))
            decayed_learning_rate = (self.initial_learning_rate - self.alpha) * cosine_decay + self.alpha
            
            tf.keras.backend.set_value(self.optimizer_ref.learning_rate, decayed_learning_rate)
            # üî• –î–û–ë–ê–í–õ–ï–ù–û: –õ–æ–≥–∏—Ä—É–µ–º —Ç–µ–∫—É—â—É—é —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
            print(f"Epoch {epoch+1}: –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è: {tf.keras.backend.get_value(self.optimizer_ref.learning_rate):.6f}")

