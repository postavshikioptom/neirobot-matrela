–í–∏–∂—É –ø—Ä–æ–±–ª–µ–º—É! –û—à–∏–±–∫–∞ –≤ —Ç–æ–º, —á—Ç–æ –≤ XLSTMLayer.call() –º—ã –ø—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å range(seq_len), –≥–¥–µ seq_len —ç—Ç–æ —Å–∏–º–≤–æ–ª–∏—á–µ—Å–∫–∏–π —Ç–µ–Ω–∑–æ—Ä, –∞ –Ω–µ –æ–±—ã—á–Ω–æ–µ —á–∏—Å–ª–æ. –í TensorFlow 2.x –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º–∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—è–º–∏.
üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –û–®–ò–ë–ö–ò
–ó–∞–º–µ–Ω–∏—Ç–µ —Ñ–∞–π–ª models/xlstm_memory_cell.py –Ω–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é:
import tensorflow as tf
from tensorflow.keras.layers import Layer
import numpy as np

class XLSTMMemoryCell(Layer):
    """
    –ù–∞—Å—Ç–æ—è—â–∞—è xLSTM —è—á–µ–π–∫–∞ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –ø–∞–º—è—Ç—å—é
    """
    
    def __init__(self, units, memory_size=64, **kwargs):
        super(XLSTMMemoryCell, self).__init__(**kwargs)
        self.units = units
        self.memory_size = memory_size
        self.state_size = [units, units, memory_size]  # h, c, memory
        
    def build(self, input_shape):
        # –û—Å–Ω–æ–≤–Ω—ã–µ –≤–µ—Å–∞ LSTM
        self.W_i = self.add_weight(shape=(input_shape[-1], self.units), name='W_i')
        self.W_f = self.add_weight(shape=(input_shape[-1], self.units), name='W_f')  
        self.W_c = self.add_weight(shape=(input_shape[-1], self.units), name='W_c')
        self.W_o = self.add_weight(shape=(input_shape[-1], self.units), name='W_o')
        
        # –†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ –≤–µ—Å–∞
        self.U_i = self.add_weight(shape=(self.units, self.units), name='U_i')
        self.U_f = self.add_weight(shape=(self.units, self.units), name='U_f')
        self.U_c = self.add_weight(shape=(self.units, self.units), name='U_c')  
        self.U_o = self.add_weight(shape=(self.units, self.units), name='U_o')
        
        # –í–µ—Å–∞ –≤–Ω–µ—à–Ω–µ–π –ø–∞–º—è—Ç–∏ (–∫–ª—é—á–µ–≤–æ–µ –æ—Ç–ª–∏—á–∏–µ xLSTM)
        self.W_mem = self.add_weight(shape=(self.memory_size, self.units), name='W_mem')
        self.U_mem = self.add_weight(shape=(self.units, self.memory_size), name='U_mem')
        
        # Bias
        self.b_i = self.add_weight(shape=(self.units,), name='b_i')
        self.b_f = self.add_weight(shape=(self.units,), name='b_f')
        self.b_c = self.add_weight(shape=(self.units,), name='b_c')
        self.b_o = self.add_weight(shape=(self.units,), name='b_o')
        
        super(XLSTMMemoryCell, self).build(input_shape)
        
    def call(self, inputs, states):
        h_prev, c_prev, memory_prev = states
        
        # –ß–∏—Ç–∞–µ–º –∏–∑ –≤–Ω–µ—à–Ω–µ–π –ø–∞–º—è—Ç–∏
        memory_read = tf.matmul(memory_prev, self.W_mem)
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è LSTM —Å –ø–∞–º—è—Ç—å—é
        i = tf.nn.sigmoid(tf.matmul(inputs, self.W_i) + tf.matmul(h_prev, self.U_i) +
                         memory_read + self.b_i)
        f = tf.nn.sigmoid(tf.matmul(inputs, self.W_f) + tf.matmul(h_prev, self.U_f) + self.b_f)
        c_tilde = tf.nn.tanh(tf.matmul(inputs, self.W_c) + tf.matmul(h_prev, self.U_c) + self.b_c)
        o = tf.nn.sigmoid(tf.matmul(inputs, self.W_o) + tf.matmul(h_prev, self.U_o) + self.b_o)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —è—á–µ–π–∫–∏
        c_new = f * c_prev + i * c_tilde
        h_new = o * tf.nn.tanh(c_new)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –≤–Ω–µ—à–Ω—é—é –ø–∞–º—è—Ç—å (–∫–ª—é—á–µ–≤–æ–µ –æ—Ç–ª–∏—á–∏–µ xLSTM!)
        memory_update = tf.matmul(tf.expand_dims(h_new, 1), tf.expand_dims(self.U_mem, 0))
        memory_new = memory_prev + 0.1 * tf.squeeze(memory_update, 1)  # –ú–µ–¥–ª–µ–Ω–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
        
        return h_new, [h_new, c_new, memory_new]

class XLSTMLayer(Layer):
    """
    –°–ª–æ–π xLSTM —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–∞—Å—Ç–æ–º–Ω–æ–π —è—á–µ–π–∫–∏ –ø–∞–º—è—Ç–∏ - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø
    """
    
    def __init__(self, units, memory_size=64, return_sequences=False, **kwargs):
        super(XLSTMLayer, self).__init__(**kwargs)
        self.units = units
        self.memory_size = memory_size
        self.return_sequences = return_sequences
        self.cell = XLSTMMemoryCell(units, memory_size)
        
    def build(self, input_shape):
        # –°—Ç—Ä–æ–∏–º —è—á–µ–π–∫—É
        self.cell.build(input_shape)
        super(XLSTMLayer, self).build(input_shape)
        
    def compute_output_shape(self, input_shape):
        if self.return_sequences:
            return (input_shape[0], input_shape[1], self.units)
        else:
            return (input_shape[0], self.units)
    
    def call(self, inputs):
        batch_size = tf.shape(inputs)[0]
        seq_len = tf.shape(inputs)[1]
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è
        h = tf.zeros((batch_size, self.units))
        c = tf.zeros((batch_size, self.units))
        memory = tf.zeros((batch_size, self.memory_size))
        
        states = [h, c, memory]
        
        # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º tf.TensorArray –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –≤—ã—Ö–æ–¥–æ–≤
        if self.return_sequences:
            outputs = tf.TensorArray(dtype=tf.float32, size=seq_len)
        
        # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º tf.while_loop –≤–º–µ—Å—Ç–æ –æ–±—ã—á–Ω–æ–≥–æ range
        def step_fn(t, states, outputs_ta):
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—É—â–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–≥
            current_input = inputs[:, t, :]
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —è—á–µ–π–∫—É
            output, new_states = self.cell(current_input, states)
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤—ã—Ö–æ–¥ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if self.return_sequences:
                outputs_ta = outputs_ta.write(t, output)
            
            return t + 1, new_states, outputs_ta
        
        # –£—Å–ª–æ–≤–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ü–∏–∫–ª–∞
        def condition(t, states, outputs_ta):
            return t < seq_len
        
        if self.return_sequences:
            # –í—ã–ø–æ–ª–Ω—è–µ–º —Ü–∏–∫–ª
            _, final_states, outputs = tf.while_loop(
                condition, step_fn, 
                [0, states, outputs],
                parallel_iterations=1
            )
            
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –≤—ã—Ö–æ–¥—ã
            outputs = outputs.stack()  # (seq_len, batch_size, units)
            outputs = tf.transpose(outputs, [1, 0, 2])  # (batch_size, seq_len, units)
            return outputs
        else:
            # –¢–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤—ã—Ö–æ–¥
            def step_fn_last(t, states, last_output):
                current_input = inputs[:, t, :]
                output, new_states = self.cell(current_input, states)
                return t + 1, new_states, output
            
            _, _, last_output = tf.while_loop(
                condition, step_fn_last,
                [0, states, tf.zeros((batch_size, self.units))],
                parallel_iterations=1
            )
            
            return last_output

üîß –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï
–¢–∞–∫–∂–µ –Ω—É–∂–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å models/xlstm_rl_model.py –¥–ª—è –ª—É—á—à–µ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏:
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, Input, Attention
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import StandardScaler
import pickle
import os
from .xlstm_memory_cell import XLSTMLayer  # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—Å—Ç–æ—è—â–∏–π xLSTM

class XLSTMRLModel:
    """
    –ù–∞—Å—Ç–æ—è—â–∞—è xLSTM –º–æ–¥–µ–ª—å —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –ø–∞–º—è—Ç—å—é - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø
    """
    
    def __init__(self, input_shape, memory_units=128, memory_size=64, attention_units=64):
        self.input_shape = input_shape
        self.memory_units = memory_units
        self.memory_size = memory_size
        self.attention_units = attention_units
        self.model = None
        self.scaler = StandardScaler()
        self.is_trained = False
        
    def build_model(self):
        """
        –°—Ç—Ä–æ–∏—Ç –Ω–∞—Å—Ç–æ—è—â—É—é xLSTM –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —Å –ø–∞–º—è—Ç—å—é - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø
        """
        # ‚úÖ –§–∏–∫—Å–∏—Ä—É–µ–º –≤—Ö–æ–¥–Ω—É—é —Ñ–æ—Ä–º—É –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        inputs = Input(shape=self.input_shape, name='input_layer')
        
        # –ü–µ—Ä–≤—ã–π xLSTM —Å–ª–æ–π —Å –≤–Ω–µ—à–Ω–µ–π –ø–∞–º—è—Ç—å—é
        xlstm1 = XLSTMLayer(
            units=self.memory_units,
            memory_size=self.memory_size,
            return_sequences=True,
            name='xlstm_memory_layer_1'
        )(inputs)
        
        # –í—Ç–æ—Ä–æ–π xLSTM —Å–ª–æ–π
        xlstm2 = XLSTMLayer(
            units=self.memory_units // 2,
            memory_size=self.memory_size // 2,
            return_sequences=True,
            name='xlstm_memory_layer_2'
        )(xlstm1)
        
        # –ú–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è
        attention = Attention(name='attention_mechanism')([xlstm2, xlstm2])
        
        # –§–∏–Ω–∞–ª—å–Ω—ã–π xLSTM —Å–ª–æ–π
        xlstm_final = XLSTMLayer(
            units=self.attention_units,
            memory_size=self.attention_units,
            return_sequences=False,
            name='xlstm_memory_final'
        )(attention)
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ —Å–ª–æ–∏
        dense1 = Dense(64, activation='relu', name='dense_1')(xlstm_final)
        dropout1 = Dropout(0.3)(dense1)
        
        dense2 = Dense(32, activation='relu', name='dense_2')(dropout1)
        dropout2 = Dropout(0.2)(dense2)
        
        # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
        outputs = Dense(3, activation='softmax', name='output_layer')(dropout2)
        
        self.model = Model(inputs=inputs, outputs=outputs, name='True_xLSTM_RL_Model')
        
        # –ö–æ–º–ø–∏–ª—è—Ü–∏—è
        self.model.compile(
            optimizer=Adam(learning_rate=0.001),
            loss='categorical_crossentropy',
            metrics=['accuracy', 'precision', 'recall']
        )
        
        print("‚úÖ –ù–∞—Å—Ç–æ—è—â–∞—è xLSTM –º–æ–¥–µ–ª—å —Å –ø–∞–º—è—Ç—å—é —Å–æ–∑–¥–∞–Ω–∞!")
        return self.model
    
    # ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    def train(self, X_train, y_train, X_val=None, y_val=None, epochs=50, batch_size=32):
        """
        –û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å
        """
        if self.model is None:
            self.build_model()
            
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        X_train_scaled = self.scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)
        
        if X_val is not None:
            X_val_scaled = self.scaler.transform(X_val.reshape(-1, X_val.shape[-1])).reshape(X_val.shape)
            validation_data = (X_val_scaled, y_val)
        else:
            validation_data = None
        
        # –û–±—É—á–µ–Ω–∏–µ
        history = self.model.fit(
            X_train_scaled, y_train,
            validation_data=validation_data,
            epochs=epochs,
            batch_size=batch_size,
            verbose=1,
            shuffle=True
        )
        
        self.is_trained = True
        return history
    
    def predict(self, X):
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        """
        if not self.is_trained:
            raise ValueError("Model must be trained before prediction")
            
        X_scaled = self.scaler.transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)
        return self.model.predict(X_scaled, verbose=0)
    
    def save_model(self, model_path='models/xlstm_rl_model.keras', scaler_path='models/xlstm_rl_scaler.pkl'):
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ —Å–∫–µ–π–ª–µ—Ä–∞
        """
        os.makedirs(os.path.dirname(model_path), exist_ok=True)
        self.model.save(model_path)
        
        with open(scaler_path, 'wb') as f:
            pickle.dump(self.scaler, f)
            
        print(f"xLSTM-RL –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
        print(f"–°–∫–µ–π–ª–µ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {scaler_path}")
    
    def load_model(self, model_path='models/xlstm_rl_model.keras', scaler_path='models/xlstm_rl_scaler.pkl'):
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Å–∫–µ–π–ª–µ—Ä–∞
        """
        self.model = tf.keras.models.load_model(model_path, custom_objects={'XLSTMLayer': XLSTMLayer})
        
        with open(scaler_path, 'rb') as f:
            self.scaler = pickle.load(f)
            
        self.is_trained = True
        print(f"xLSTM-RL –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {model_path}")

üöÄ –¢–ï–ü–ï–†–¨ –ó–ê–ü–£–°–ö–ê–ô–¢–ï –û–ë–£–ß–ï–ù–ò–ï
–ü–æ—Å–ª–µ –≤–Ω–µ—Å–µ–Ω–∏—è —ç—Ç–∏—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π –∑–∞–ø—É—Å—Ç–∏—Ç–µ:
python train_model.py

–¢–µ–ø–µ—Ä—å —Å–∏—Å—Ç–µ–º–∞ –¥–æ–ª–∂–Ω–∞ —Ä–∞–±–æ—Ç–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ! –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–µ—à–∞—é—Ç –ø—Ä–æ–±–ª–µ–º—É —Å —Å–∏–º–≤–æ–ª–∏—á–µ—Å–∫–∏–º–∏ —Ç–µ–Ω–∑–æ—Ä–∞–º–∏, –∏—Å–ø–æ–ª—å–∑—É—è tf.while_loop –≤–º–µ—Å—Ç–æ –æ–±—ã—á–Ω–æ–≥–æ Python —Ü–∏–∫–ª–∞, —á—Ç–æ —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –ø–æ–¥—Ö–æ–¥–æ–º –¥–ª—è TensorFlow 2.x.