import numpy as np
import pandas as pd
from sklearn.preprocessing import RobustScaler
import pickle
import os
import talib # üî• –î–û–ë–ê–í–õ–ï–ù–û: –ò–º–ø–æ—Ä—Ç TA-Lib
import tensorflow as tf # üî• –î–û–ë–ê–í–õ–ï–ù–û: –ò–º–ø–æ—Ä—Ç Tensorflow
import config # üî• –î–û–ë–ê–í–õ–ï–ù–û: –ò–º–ø–æ—Ä—Ç config –¥–ª—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
import gc
from collections import deque
import logging

def log_nan_inf_stats(df, stage_name="Unknown"):
    """üî• –î–û–ë–ê–í–õ–ï–ù–û: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ NaN –∏ inf –∑–Ω–∞—á–µ–Ω–∏–π"""
    nan_stats = {}
    inf_stats = {}
    
    for col in df.columns:
        if df[col].dtype in ['float64', 'float32', 'int64', 'int32']:
            nan_count = df[col].isna().sum()
            inf_count = np.isinf(df[col]).sum()
            
            if nan_count > 0:
                nan_stats[col] = {
                    'count': nan_count,
                    'percentage': nan_count / len(df) * 100
                }
            
            if inf_count > 0:
                inf_stats[col] = {
                    'count': inf_count,
                    'percentage': inf_count / len(df) * 100
                }
    
    if nan_stats:
        print(f"‚ö†Ô∏è NaN –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –≤ {stage_name}:")
        for col, stats in nan_stats.items():
            print(f"  {col}: {stats['count']} ({stats['percentage']:.2f}%)")
    
    if inf_stats:
        print(f"‚ö†Ô∏è Inf –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –≤ {stage_name}:")
        for col, stats in inf_stats.items():
            print(f"  {col}: {stats['count']} ({stats['percentage']:.2f}%)")
    
    return nan_stats, inf_stats

def safe_fill_nan_inf(df, method='median'):
    """üî• –î–û–ë–ê–í–õ–ï–ù–û: –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ NaN –∏ inf –∑–Ω–∞—á–µ–Ω–∏–π"""
    df_clean = df.copy()
    
    # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–æ –æ—á–∏—Å—Ç–∫–∏
    nan_stats, inf_stats = log_nan_inf_stats(df_clean, "–î–æ –æ—á–∏—Å—Ç–∫–∏")
    
    for col in df_clean.columns:
        if df_clean[col].dtype in ['float64', 'float32', 'int64', 'int32']:
            # –ó–∞–º–µ–Ω—è–µ–º inf –Ω–∞ NaN
            df_clean[col] = df_clean[col].replace([np.inf, -np.inf], np.nan)
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–µ—Ç–æ–¥–∞
            if method == 'median':
                fill_value = df_clean[col].median()
                if pd.isna(fill_value):
                    # –ï—Å–ª–∏ –º–µ–¥–∏–∞–Ω–∞ —Ç–æ–∂–µ NaN, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ä–µ–¥–Ω–µ–µ
                    fill_value = df_clean[col].mean()
                    if pd.isna(fill_value):
                        # –ï—Å–ª–∏ –∏ —Å—Ä–µ–¥–Ω–µ–µ NaN, –∏—Å–ø–æ–ª—å–∑—É–µ–º 0
                        fill_value = 0.0
            elif method == 'mean':
                fill_value = df_clean[col].mean()
                if pd.isna(fill_value):
                    fill_value = 0.0
            else:  # method == 'zero'
                fill_value = 0.0
            
            df_clean[col] = df_clean[col].fillna(fill_value)
    
    # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
    post_nan, post_inf = log_nan_inf_stats(df_clean, "–ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏")
    # if for any important indicator post_nan still > 0:
    for col, stats in post_nan.items():
        if stats['percentage'] > 0.5:
            print(f"‚ö†Ô∏è –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ {col} –∏–º–µ–µ—Ç {stats['percentage']:.2f}% NaN ‚Äî –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö")
    
    return df_clean

class FeatureEngineering:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏, –≤–∫–ª—é—á–∞—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
    """
    def __init__(self, sequence_length=60):
        self.sequence_length = sequence_length
        self.scaler = RobustScaler()  # –ë–æ–ª–µ–µ —É—Å—Ç–æ–π—á–∏–≤ –∫ –≤—ã–±—Ä–æ—Å–∞–º —á–µ–º StandardScaler
        # üî• –ò–ó–ú–ï–ù–ï–ù–û: –ò—Å—Ö–æ–¥–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        self.base_features = ['open', 'high', 'low', 'close', 'volume', 'turnover']
        self.feature_columns = list(self.base_features) # –ë—É–¥—É—Ç –æ–±–Ω–æ–≤–ª–µ–Ω—ã –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        # üî• –î–û–ë–ê–í–õ–ï–ù–û: –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.indicator_cache = {}
        self.cache_max_size = 1000
        self.fallback_retry_count = 0
        self.max_fallback_retries = 3
    
    def _validate_data_for_indicators(self, df):
        """üî• –î–û–ë–ê–í–õ–ï–ù–û: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"""
        if df is None or df.empty:
            return False, "–ü—É—Å—Ç–æ–π DataFrame"
        
        required_cols = ['open', 'high', 'low', 'close', 'volume']
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            return False, f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {missing_cols}"
        
        if len(df) < config.RSI_PERIOD + 5:
            return False, f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(df)} < {config.RSI_PERIOD + 5}"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ NaN
        for col in required_cols:
            nan_percent = df[col].isna().sum() / len(df)
            if nan_percent > 0.5:
                return False, f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ NaN –≤ –∫–æ–ª–æ–Ω–∫–µ {col}: {nan_percent:.2%}"
        
        return True, "OK"
    
    def _get_cache_key(self, df):
        """üî• –î–û–ë–ê–í–õ–ï–ù–û: –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª—é—á–∞ –∫—ç—à–∞ –¥–ª—è DataFrame"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º hash –æ—Ç –ø–µ—Ä–≤—ã—Ö/–ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∏ —Ä–∞–∑–º–µ—Ä–∞
            first_vals = tuple(df.iloc[0][['open', 'high', 'low', 'close']].values)
            last_vals = tuple(df.iloc[-1][['open', 'high', 'low', 'close']].values)
            return hash((first_vals, last_vals, len(df)))
        except:
            return None
        
    def _add_technical_indicators(self, df):
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —Å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        """
        try:
            # üî• –î–û–ë–ê–í–õ–ï–ù–û: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
            is_valid, error_msg = self._validate_data_for_indicators(df)
            if not is_valid:
                print(f"–í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –Ω–µ –ø—Ä–æ–π–¥–µ–Ω–∞: {error_msg}")
                return self._create_fallback_indicators_df()
            
            # üî• –î–û–ë–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞
            cache_key = self._get_cache_key(df)
            if cache_key and cache_key in self.indicator_cache:
                print("–ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã")
                cached_result = self.indicator_cache[cache_key].copy()
                return cached_result
            
            # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ —á–∏—Å–ª–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
            for col in ['open', 'high', 'low', 'close', 'volume']:
                df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –ú–∞—Å—Å–æ–≤—ã–π —Ä–∞—Å—á–µ—Ç –≤—Å–µ—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
            indicators_success = self._calculate_all_indicators_batch(df)
            
            if not indicators_success:
                print("–û—à–∏–±–∫–∞ –ø—Ä–∏ –º–∞—Å—Å–æ–≤–æ–º —Ä–∞—Å—á–µ—Ç–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
                return self._create_fallback_indicators_df()
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            self.feature_columns = self.base_features + [
                # –¢—Ä–µ–Ω–¥–æ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
                'EMA_7', 'EMA_14', 'EMA_21',
                'MACD', 'MACDSIGNAL', 'MACDHIST',
                'KAMA', 'SUPERTREND',
                
                # Momentum –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
                'RSI', 'CMO', 'ROC',
                
                # Volume –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
                'OBV', 'MFI',
                
                # Volatility –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
                'ATR', 'NATR',
                
                # Statistical –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
                'STDDEV',
                
                # Cycle –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
                'HT_DCPERIOD', 'HT_SINE', 'HT_LEADSINE'
            ]
            
            # üî• –î–û–ë–ê–í–õ–ï–ù–û: –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if cache_key and len(self.indicator_cache) < self.cache_max_size:
                self.indicator_cache[cache_key] = df.copy()
            elif len(self.indicator_cache) >= self.cache_max_size:
                # –û—á–∏—â–∞–µ–º –∫—ç—à –ø—Ä–∏ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–∏
                self.indicator_cache.clear()
                gc.collect()
            
        except Exception as e:
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ _add_technical_indicators: {e}")
            return self._create_fallback_indicators_df()
        
        # –ù–∞–¥—ë–∂–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ NaN
        try:
            df = safe_fill_nan_inf(df, method='median')
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ NaN/inf: {e}")
            df = df.fillna(0)
        
        return df
    
    def _calculate_all_indicators_batch(self, df):
        """üî• –û–ë–ù–û–í–õ–ï–ù–û: –ú–∞—Å—Å–æ–≤—ã–π —Ä–∞—Å—á–µ—Ç –≤—Å–µ—Ö –Ω–æ–≤—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤"""
        try:
            # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –∑–∞–ø–æ–ª–Ω—è–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è –≤ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            for col in ['open', 'high', 'low', 'close', 'volume']:
                if col in df.columns:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º forward fill, –∑–∞—Ç–µ–º backward fill –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è NaN
                    df[col] = df[col].ffill().bfill()
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ float64 –¥–ª—è talib
            close_prices = df['close'].astype(np.float64).values
            high_prices = df['high'].astype(np.float64).values
            low_prices = df['low'].astype(np.float64).values
            volume_prices = df['volume'].astype(np.float64).values
            
            # –ó–∞–º–µ–Ω—è–µ–º –Ω—É–ª–µ–≤—ã–µ —Ü–µ–Ω—ã –Ω–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
            close_prices = np.where(close_prices <= 0, 1e-8, close_prices)
            high_prices = np.where(high_prices <= 0, 1e-8, high_prices)
            low_prices = np.where(low_prices <= 0, 1e-8, low_prices)
            volume_prices = np.where(volume_prices <= 0, 1e-8, volume_prices)
            
            # –ú–∞—Å—Å–æ–≤—ã–π —Ä–∞—Å—á–µ—Ç –≤—Å–µ—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
            indicators = {}
            
            # === –¢–†–ï–ù–î–û–í–´–ï –ò–ù–î–ò–ö–ê–¢–û–†–´ ===
            
            # EMA (7, 14, 21)
            for period in config.EMA_PERIODS:
                indicators[f'EMA_{period}'] = talib.EMA(close_prices, timeperiod=period)
            
            # MACD (—Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è)
            macd, macdsignal, macdhist = talib.MACD(
                close_prices,
                fastperiod=config.MACD_FASTPERIOD,
                slowperiod=config.MACD_SLOWPERIOD,
                signalperiod=config.MACD_SIGNALPERIOD
            )
            indicators['MACD'] = macd
            indicators['MACDSIGNAL'] = macdsignal
            indicators['MACDHIST'] = macdhist
            
            # KAMA
            indicators['KAMA'] = talib.KAMA(close_prices, timeperiod=config.KAMA_PERIOD)
            
            # SuperTrend (–∫–∞—Å—Ç–æ–º–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è)
            indicators['SUPERTREND'] = self._calculate_supertrend(
                high_prices, low_prices, close_prices, 
                config.SUPERTREND_PERIOD, config.SUPERTREND_MULTIPLIER
            )
            
            # === MOMENTUM –ò–ù–î–ò–ö–ê–¢–û–†–´ ===
            
            # RSI (—Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è)
            indicators['RSI'] = talib.RSI(close_prices, timeperiod=config.RSI_PERIOD)
            
            # CMO
            indicators['CMO'] = talib.CMO(close_prices, timeperiod=config.CMO_PERIOD)
            
            # ROC
            indicators['ROC'] = talib.ROC(close_prices, timeperiod=config.ROC_PERIOD)
            
            # === VOLUME –ò–ù–î–ò–ö–ê–¢–û–†–´ ===
            
            # OBV
            indicators['OBV'] = talib.OBV(close_prices, volume_prices)
            
            # MFI
            indicators['MFI'] = talib.MFI(
                high_prices, low_prices, close_prices, volume_prices, 
                timeperiod=config.RSI_PERIOD
            )
            
            # === VOLATILITY –ò–ù–î–ò–ö–ê–¢–û–†–´ ===
            
            # ATR
            indicators['ATR'] = talib.ATR(
                high_prices, low_prices, close_prices, 
                timeperiod=config.ATR_PERIOD
            )
            
            # NATR
            indicators['NATR'] = talib.NATR(
                high_prices, low_prices, close_prices, 
                timeperiod=config.NATR_PERIOD
            )
            
            # === STATISTICAL –ò–ù–î–ò–ö–ê–¢–û–†–´ ===
            
            # STDDEV
            indicators['STDDEV'] = talib.STDDEV(close_prices, timeperiod=config.STDDEV_PERIOD)
            
            # === CYCLE –ò–ù–î–ò–ö–ê–¢–û–†–´ ===
            
            # HT_DCPERIOD
            indicators['HT_DCPERIOD'] = talib.HT_DCPERIOD(close_prices)
            
            # HT_SINE
            sine, leadsine = talib.HT_SINE(close_prices)
            indicators['HT_SINE'] = sine
            indicators['HT_LEADSINE'] = leadsine
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –≤ DataFrame –∏ –∑–∞–ø–æ–ª–Ω—è–µ–º NaN
            for name, values in indicators.items():
                df[name] = values
                # –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è –º–µ–¥–∏–∞–Ω–æ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞
                if np.isnan(values).any():
                    median_value = np.nanmedian(values)
                    df[name] = df[name].fillna(median_value)
            
            return True
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –º–∞—Å—Å–æ–≤–æ–º —Ä–∞—Å—á–µ—Ç–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤: {e}")
            return False
    
    def _calculate_supertrend(self, high, low, close, period=10, multiplier=3.0):
        """–†–∞—Å—á–µ—Ç SuperTrend –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞"""
        try:
            # –†–∞—Å—á–µ—Ç ATR
            atr = talib.ATR(high, low, close, timeperiod=period)
            
            # –†–∞—Å—á–µ—Ç –±–∞–∑–æ–≤—ã—Ö –ª–∏–Ω–∏–π
            hl2 = (high + low) / 2
            upper_band = hl2 + (multiplier * atr)
            lower_band = hl2 - (multiplier * atr)
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Å—Å–∏–≤–æ–≤
            supertrend = np.zeros_like(close)
            direction = np.ones_like(close)
            
            # –†–∞—Å—á–µ—Ç SuperTrend
            for i in range(1, len(close)):
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Ä—Ö–Ω–µ–π –ø–æ–ª–æ—Å—ã
                if upper_band[i] < upper_band[i-1] or close[i-1] > upper_band[i-1]:
                    upper_band[i] = upper_band[i]
                else:
                    upper_band[i] = upper_band[i-1]
                
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–∏–∂–Ω–µ–π –ø–æ–ª–æ—Å—ã
                if lower_band[i] > lower_band[i-1] or close[i-1] < lower_band[i-1]:
                    lower_band[i] = lower_band[i]
                else:
                    lower_band[i] = lower_band[i-1]
                
                # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞
                if close[i] <= lower_band[i-1]:
                    direction[i] = -1
                elif close[i] >= upper_band[i-1]:
                    direction[i] = 1
                else:
                    direction[i] = direction[i-1]
                
                # –†–∞—Å—á–µ—Ç SuperTrend
                if direction[i] == 1:
                    supertrend[i] = lower_band[i]
                else:
                    supertrend[i] = upper_band[i]
            
            return supertrend
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ SuperTrend: {e}")
            return np.zeros_like(close)

    def _create_fallback_indicators_df(self, df=None):
        """üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –°–æ–∑–¥–∞–µ—Ç DataFrame —Å fallback –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –±–µ–∑ —Ä–µ–∫—É—Ä—Å–∏–∏"""
        self.fallback_retry_count += 1
        
        if self.fallback_retry_count > self.max_fallback_retries:
            print(f"‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ fallback: {self.max_fallback_retries}")
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö –≤—ã–∑–æ–≤–æ–≤
            self.fallback_retry_count = 0
            return None
        
        if df is None:
            # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π DataFrame
            df = pd.DataFrame({
                'open': [100.0],
                'high': [101.0],
                'low': [99.0],
                'close': [100.5],
                'volume': [1000.0],
                'turnover': [100000.0]
            })
        
        # –î–æ–±–∞–≤–ª—è–µ–º fallback –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —Å –º–µ–¥–∏–∞–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        # –¢—Ä–µ–Ω–¥–æ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        for period in config.EMA_PERIODS:
            df[f'EMA_{period}'] = 100.0
        df['MACD'] = 0.0
        df['MACDSIGNAL'] = 0.0
        df['MACDHIST'] = 0.0
        df['KAMA'] = 100.0
        df['SUPERTREND'] = 100.0
        
        # Momentum –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        df['RSI'] = 50.0
        df['CMO'] = 0.0
        df['ROC'] = 0.0
        
        # Volume –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        df['OBV'] = 0.0
        df['MFI'] = 50.0
        
        # Volatility –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        df['ATR'] = 1.0
        df['NATR'] = 1.0
        
        # Statistical –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        df['STDDEV'] = 1.0
        
        # Cycle –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        df['HT_DCPERIOD'] = 20.0
        df['HT_SINE'] = 0.0
        df['HT_LEADSINE'] = 0.0
        
        self.feature_columns = self.base_features + [
            # –¢—Ä–µ–Ω–¥–æ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            'EMA_7', 'EMA_14', 'EMA_21',
            'MACD', 'MACDSIGNAL', 'MACDHIST',
            'KAMA', 'SUPERTREND',
            
            # Momentum –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            'RSI', 'CMO', 'ROC',
            
            # Volume –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            'OBV', 'MFI',
            
            # Volatility –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            'ATR', 'NATR',
            
            # Statistical –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            'STDDEV',
            
            # Cycle –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            'HT_DCPERIOD', 'HT_SINE', 'HT_LEADSINE'
        ]
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è
        self.fallback_retry_count = 0
        
        return df

    def prepare_data(self, df):
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö: –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤, –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ timestamp –≤ —á–∏—Å–ª–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        if 'timestamp' in df.columns:
            if not pd.api.types.is_numeric_dtype(df['timestamp']):
                print(f"‚ö†Ô∏è timestamp –Ω–µ –≤ —á–∏—Å–ª–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ: {df['timestamp'].dtype}, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º")
                df['timestamp'] = pd.to_numeric(df['timestamp'])
            print(f"–¢–∏–ø timestamp: {df['timestamp'].dtype}")
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ timestamp (—á–∏—Å–ª–æ–≤–æ–º—É)
        df = df.sort_values('timestamp')
        
        # üî• –ò–ó–ú–ï–ù–ï–ù–û: –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        df_with_indicators = self._add_technical_indicators(df.copy())
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç
        for col in self.feature_columns:
            df_with_indicators[col] = pd.to_numeric(df_with_indicators[col], errors='coerce')
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        data = df_with_indicators[self.feature_columns].values
        
        # –û–±—É—á–∞–µ–º —Å–∫–µ–π–ª–µ—Ä –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö (—Ç–µ–ø–µ—Ä—å –≤–∫–ª—é—á–∞—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã)
        scaled_data = self.scaler.fit_transform(data)
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        X, y_close = self._create_sequences(scaled_data)
        
        return X, y_close, df_with_indicators
    
    def prepare_test_data(self, df):
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —É–∂–µ –æ–±—É—á–µ–Ω–Ω–æ–≥–æ —Å–∫–µ–π–ª–µ—Ä–∞ –∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        """
        df = df.sort_values('timestamp')
        
        # üî• –ò–ó–ú–ï–ù–ï–ù–û: –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        df_with_indicators = self._add_technical_indicators(df.copy())
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç
        for col in self.feature_columns:
            df_with_indicators[col] = pd.to_numeric(df_with_indicators[col], errors='coerce')
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        data = df_with_indicators[self.feature_columns].values
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —É–∂–µ –æ–±—É—á–µ–Ω–Ω—ã–π —Å–∫–µ–π–ª–µ—Ä
        scaled_data = self.scaler.transform(data)
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        X, y_close = self._create_sequences(scaled_data)
        
        return X, y_close, df_with_indicators
    
    def _create_sequences(self, data):
        """–°–æ–∑–¥–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        try:
            if data is None or len(data) == 0:
                print("‚ùå –ü—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥–∞–Ω—ã –≤ _create_sequences")
                return np.array([]), np.array([])
            
            # print(f"–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –∏–∑ –¥–∞–Ω–Ω—ã—Ö —Ñ–æ—Ä–º—ã {data.shape}") # üî• –£–±—Ä–∞–Ω–æ –ª–∏—à–Ω–µ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
            
            if len(data) <= self.sequence_length:
                print(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π: {len(data)} <= {self.sequence_length}")
                if len(data) > 10:
                    reduced_sequence_length = len(data) - 5
                    print(f"–ü—Ä–æ–±—É–µ–º —Å–æ–∑–¥–∞—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å —É–º–µ–Ω—å—à–µ–Ω–Ω–æ–π –¥–ª–∏–Ω–æ–π {reduced_sequence_length}")
                    X = []
                    y_close = []
                    
                    close_index = 3
                    try:
                        if hasattr(self, 'base_features') and 'close' in self.base_features:
                            close_index = self.base_features.index('close')
                    except (ValueError, AttributeError):
                        pass
                    
                    X.append(data[:reduced_sequence_length])
                    y_close.append(data[reduced_sequence_length, close_index])
                    
                    return np.array(X), np.array(y_close)
                else:
                    return np.array([]), np.array([])
            
            X = []
            y_close = []
            
            close_index = 3
            try:
                if hasattr(self, 'base_features') and 'close' in self.base_features:
                    close_index = self.base_features.index('close')
            except (ValueError, AttributeError):
                close_index = 3
            
            for i in range(len(data) - self.sequence_length):
                try:
                    # –°–æ–∑–¥–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                    sequence = data[i:i+self.sequence_length]
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ NaN/inf –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                    if np.isnan(sequence).any() or np.isinf(sequence).any():
                        print(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω NaN/inf –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ {i}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                        continue
                    
                    X.append(sequence)
                    y_close.append(data[i+self.sequence_length, close_index])
                except (IndexError, ValueError) as e:
                    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ {i}: {e}")
                    continue
            
            if len(X) == 0:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
                return np.array([]), np.array([])
            
            return np.array(X), np.array(y_close)
            
        except Exception as e:
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ _create_sequences: {e}")
            return np.array([]), np.array([])
    
    def calculate_adaptive_threshold(self, df, base_threshold=None):
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ —Ä—ã–Ω–∫–∞
        
        Args:
            df (pd.DataFrame): DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ —Ü–µ–Ω
            base_threshold (float, optional): –ë–∞–∑–æ–≤—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è. –ï—Å–ª–∏ None, –±–µ—Ä–µ—Ç—Å—è –∏–∑ config.
            
        Returns:
            float: –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤
        """
        # –ï—Å–ª–∏ base_threshold –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω, –±–µ—Ä–µ–º –µ–≥–æ –∏–∑ config
        if base_threshold is None:
            base_threshold = config.PRICE_CHANGE_THRESHOLD
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
            required_cols = ['high', 'low', 'close']
            for col in required_cols:
                if col not in df.columns:
                    print(f"–û—à–∏–±–∫–∞: –∫–æ–ª–æ–Ω–∫–∞ {col} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö")
                    return base_threshold
            
            # –†–∞—Å—á–µ—Ç True Range –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö N —Å–≤–µ—á–µ–π
            n_periods = min(14, len(df) - 1)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–µ—Ä–∏–æ–¥ ATR=14 –∏–ª–∏ –º–µ–Ω—å—à–µ, –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ
            
            tr_values = []
            for i in range(1, n_periods + 1):
                if i >= len(df):
                    break
                    
                high = df['high'].iloc[-i]
                low = df['low'].iloc[-i]
                prev_close = df['close'].iloc[-(i+1)]
                
                tr1 = high - low
                tr2 = abs(high - prev_close)
                tr3 = abs(low - prev_close)
                
                tr = max(tr1, tr2, tr3)
                tr_values.append(tr)
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º ATR
            if tr_values:
                atr = sum(tr_values) / len(tr_values)
            else:
                print("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ ATR, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π –ø–æ—Ä–æ–≥")
                return base_threshold
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º ATR –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω—ã
            last_price = df['close'].iloc[-1]
            if last_price > 0:
                normalized_atr = atr / last_price
            else:
                normalized_atr = 0.001
            
            # üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –ë–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –º–Ω–æ–∂–∏—Ç–µ–ª—è –¥–ª—è –Ω–∏–∑–∫–æ–≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã—Ö –∞–∫—Ç–∏–≤–æ–≤
            # –£–º–µ–Ω—å—à–∞–µ–º –º–Ω–æ–∂–∏—Ç–µ–ª—å, —á—Ç–æ–±—ã –Ω–µ –¥–µ–ª–∞—Ç—å –ø–æ—Ä–æ–≥ —Å–ª–∏—à–∫–æ–º —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–º
            atr_multiplier = config.ADAPTIVE_THRESHOLD_MULTIPLIER
            # –ï—Å–ª–∏ normalized_atr –æ—á–µ–Ω—å –Ω–∏–∑–∫–∏–π, –º—ã –º–æ–∂–µ–º –Ω–µ–º–Ω–æ–≥–æ —É–≤–µ–ª–∏—á–∏—Ç—å –º–Ω–æ–∂–∏—Ç–µ–ª—å,
            # –Ω–æ –Ω–µ —Ç–∞–∫ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ, –∫–∞–∫ —Ä–∞–Ω—å—à–µ, —á—Ç–æ–±—ã –Ω–µ –ø–æ–ª—É—á–∏—Ç—å —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ BUY/SELL
            if normalized_atr < 0.0005:  # –ï—Å–ª–∏ ATR –º–µ–Ω—å—à–µ 0.05%
                atr_multiplier = 0.9   # –ù–µ–º–Ω–æ–≥–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –º–Ω–æ–∂–∏—Ç–µ–ª—å
            elif normalized_atr < 0.001: # –ï—Å–ª–∏ ATR –º–µ–Ω—å—à–µ 0.1%
                atr_multiplier = 0.8
                
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
            adaptive_threshold = max(
                config.ADAPTIVE_THRESHOLD_MIN, 
                min(config.ADAPTIVE_THRESHOLD_MAX, normalized_atr * atr_multiplier)
            )
            
            # üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –£–±–∏—Ä–∞–µ–º –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞,
            # —Ç–∞–∫ –∫–∞–∫ —Ç–µ–ø–µ—Ä—å –º—ã —Ö–æ—Ç–∏–º –µ–≥–æ –Ω–µ–º–Ω–æ–≥–æ —É–≤–µ–ª–∏—á–∏—Ç—å –¥–ª—è HOLD
            # recommended_threshold_from_log = self._get_recommended_threshold_from_data(df, future_window=config.FUTURE_WINDOW)
            # if recommended_threshold_from_log is not None and recommended_threshold_from_log < adaptive_threshold * 0.5:
            #     print(f"–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Å–Ω–∏–∂–∞–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–æ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω–æ–≥–æ: {recommended_threshold_from_log:.6f}")
            #     adaptive_threshold = recommended_threshold_from_log
                
            print(f"[ADAPTIVE] Base threshold: {base_threshold:.6f}, ATR: {normalized_atr:.6f}, "
                  f"Adaptive threshold: {adaptive_threshold:.6f}")
            
            return adaptive_threshold
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞: {e}")
            return base_threshold

    def _get_recommended_threshold_from_data(self, df, future_window):
        """
        –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞ –∏–∑ –¥–∞–Ω–Ω—ã—Ö,
        —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–∏–º–µ—Ä–Ω–æ 30% —Å–∏–≥–Ω–∞–ª–æ–≤.
        """
        try:
            prices = df['close'].values
            if len(prices) <= future_window:
                return None
                
            sample_changes = []
            for j in range(len(prices) - future_window):
                cp = float(prices[j])
                fp = float(prices[j+future_window])
                if cp == 0:
                    pct = 0.0
                else:
                    pct = (fp - cp) / cp
                sample_changes.append(pct)
            
            changes_abs = np.abs(sample_changes)
            if not changes_abs.any(): # –ï—Å–ª–∏ –≤—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω—É–ª–µ–≤—ã–µ
                return 0.0001 # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥
                
            changes_sorted = np.sort(changes_abs)
            
            # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Ä–æ–≥, –∫–æ—Ç–æ—Ä—ã–π –±—ã –¥–∞–ª –ø—Ä–∏–º–µ—Ä–Ω–æ 30% —Å–∏–≥–Ω–∞–ª–æ–≤ (–Ω–µ HOLD)
            target_idx = int(len(changes_sorted) * 0.7)  # 70-–π –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å
            if target_idx < len(changes_sorted):
                return changes_sorted[target_idx]
            else:
                return None
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞: {e}")
            return None

    def create_trading_labels(self, df):
        """
        –°–æ–∑–¥–∞–µ—Ç –º–µ—Ç–∫–∏ –¥–ª—è —Ç–æ—Ä–≥–æ–≤–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±—É–¥—É—â–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π —Ü–µ–Ω—ã
        —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ config.py.
        
        Args:
            df (pd.DataFrame): DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ —Ü–µ–Ω
            
        Returns:
            np.array: –ú–∞—Å—Å–∏–≤ –º–µ—Ç–æ–∫ (0: SELL, 1: HOLD, 2: BUY)
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ timestamp, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
        if 'timestamp' in df.columns:
            if not pd.api.types.is_numeric_dtype(df['timestamp']):
                print(f"‚ö†Ô∏è timestamp –Ω–µ –≤ —á–∏—Å–ª–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ: {df['timestamp'].dtype}, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º")
                df['timestamp'] = pd.to_numeric(df['timestamp'])
            df = df.sort_values('timestamp')
        
        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º threshold –∏–∑ config.py
        adaptive_threshold = self.calculate_adaptive_threshold(df, config.PRICE_CHANGE_THRESHOLD)
        
        prices = df['close'].values
        labels = []

        # DEBUG: –ª–æ–≥ –≤—Ö–æ–¥–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ —Å—Ä–µ–∑–∞ —Ü–µ–Ω
        try:
            print(f"[LABELS DEBUG] adaptive_threshold={adaptive_threshold}, future_window={config.FUTURE_WINDOW}, len(prices)={len(prices)}")
            # print("[LABELS DEBUG] first 8 closes:", prices[:8].tolist())
            # print("[LABELS DEBUG] last 8 closes:", prices[-8:].tolist())
        except Exception:
            pass

        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º future_window –∏–∑ config.py
        for i in range(len(prices) - config.FUTURE_WINDOW):
            current_price = float(prices[i])
            future_price = float(prices[i + config.FUTURE_WINDOW])

            # –ó–∞—â–∏—Ç–∞ –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
            if current_price == 0 or np.isnan(current_price) or np.isinf(current_price):
                price_change = 0.0
            else:
                price_change = (future_price - current_price) / float(current_price)

        # DEBUG –¥–ª—è –ø–µ—Ä–≤—ã—Ö 20 –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
        # if i < 20:
        #     print(f"[LABELS DEBUG] i={i}, cur={current_price:.6f}, fut={future_price:.6f}, change={price_change:.6f}")

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤
            if price_change > adaptive_threshold:
                labels.append(2)  # BUY
            elif price_change < -adaptive_threshold:
                labels.append(0)  # SELL
            else:
                labels.append(1)  # HOLD

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –º–µ—Ç–æ–∫
        vals, counts = np.unique(labels, return_counts=True)
        dist = {int(v): int(c) for v, c in zip(vals, counts)}
        print(f"[LABELS DEBUG] label distribution (SELL=0,HOLD=1,BUY=2): {dist}")
        
        # –ê–Ω–∞–ª–∏–∑ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞
        total = len(labels)
        hold_count = dist.get(1, 0)
        hold_percentage = hold_count / total if total > 0 else 0
        
        if hold_percentage > 0.8:
            print(f"[HOLD WARNING] –í—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç HOLD –º–µ—Ç–æ–∫: {hold_percentage:.2%}")
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π —Ü–µ–Ω—ã –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
            if total > 0:
                sample_changes = []
                # üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º config.FUTURE_WINDOW
                for j in range(min(200, len(prices) - config.FUTURE_WINDOW)):
                    cp = float(prices[j])
                    fp = float(prices[j+config.FUTURE_WINDOW])
                    if cp == 0:
                        pct = 0.0
                    else:
                        pct = (fp - cp) / cp
                    sample_changes.append(pct)
                
                # print(f"[HOLD DEBUG] Symbol likely all-HOLD. sample changes (first 50): {np.array(sample_changes)[:50].tolist()}")
                # print(f"[HOLD DEBUG] Change stats: min={np.min(sample_changes):.6f}, max={np.max(sample_changes):.6f}, "
                #       f"mean={np.mean(sample_changes):.6f}, std={np.std(sample_changes):.6f}")
                print(f"[HOLD DEBUG] Current adaptive threshold: {adaptive_threshold:.6f}")
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º, –∫–∞–∫–æ–π –ø–æ—Ä–æ–≥ –Ω—É–∂–µ–Ω –¥–ª—è –±–æ–ª–µ–µ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
                changes_abs = np.abs(sample_changes)
                changes_sorted = np.sort(changes_abs)
                
                # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Ä–æ–≥, –∫–æ—Ç–æ—Ä—ã–π –±—ã –¥–∞–ª –ø—Ä–∏–º–µ—Ä–Ω–æ 30% —Å–∏–≥–Ω–∞–ª–æ–≤ (–Ω–µ HOLD)
                target_idx = int(len(changes_sorted) * 0.7)  # 70-–π –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å
                if target_idx < len(changes_sorted):
                    suggested_threshold = changes_sorted[target_idx]
                    print(f"[HOLD DEBUG] –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è ~30% —Å–∏–≥–Ω–∞–ª–æ–≤ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –ø–æ—Ä–æ–≥: {suggested_threshold:.6f}")
        
        return np.array(labels)
    
    def prepare_supervised_data(self, df):
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è supervised learning (—ç—Ç–∞–ø 1)
        —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –ø–æ—Ä–æ–≥–æ–≤.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ config.py.
        
        Args:
            df (pd.DataFrame): DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ —Ü–µ–Ω
            
        Returns:
            tuple: (X, labels) - –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –º–µ—Ç–∫–∏
        """
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ (–¥–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã, –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º)
        X, _, processed_df = self.prepare_data(df)
        
        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∫–∏ –±–µ–∑ –ø–µ—Ä–µ–¥–∞—á–∏ threshold –∏ future_window
        labels = self.create_trading_labels(processed_df)
        
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –¥–ª–∏–Ω—ã X –∏ labels —Å–æ–≤–ø–∞–¥–∞—é—Ç
        min_len = min(len(X), len(labels))
        print(f"[PREPARE DEBUG] before trim: len(X)={len(X)}, len(labels)={len(labels)}, using min_len={min_len}")
        X = X[:min_len]
        labels = labels[:min_len]
        
        # –í—ã–≤–æ–¥–∏–º –ø—Ä–∏–º–µ—Ä –ø–µ—Ä–≤—ã—Ö 30 –º–µ—Ç–æ–∫
        print(f"[PREPARE DEBUG] labels sample (first 30): {labels[:30].tolist()}")
        
        return X, labels
    
    def save_scaler(self, path='models'):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–±—É—á–µ–Ω–Ω—ã–π —Å–∫–µ–π–ª–µ—Ä
        """
        if not os.path.exists(path):
            os.makedirs(path)
        
        with open(os.path.join(path, 'scaler.pkl'), 'wb') as f:
            pickle.dump(self.scaler, f)
        
        print(f"–°–∫–µ–π–ª–µ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {path}/scaler.pkl")

    def load_scaler(self, path='models'):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—ã–π —Å–∫–µ–π–ª–µ—Ä
        """
        scaler_path = os.path.join(path, 'scaler.pkl')
        
        if os.path.exists(scaler_path):
            with open(scaler_path, 'rb') as f:
                self.scaler = pickle.load(f)
            print("–°–∫–µ–π–ª–µ—Ä —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω")
            return True
        else:
            print("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π —Å–∫–µ–π–ª–µ—Ä")
            return False