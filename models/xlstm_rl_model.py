import tensorflow as tf
from tensorflow.keras import layers, models
import numpy as np
import os
import tensorflow.keras.backend as K
import gc

# –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –∏–º–ø–æ—Ä—Ç
try:
    from models.xlstm_memory_cell import XLSTMMemoryCell
except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ XLSTMMemoryCell: {e}")
    print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª models/xlstm_memory_cell.py —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
    raise ImportError("XLSTMMemoryCell –Ω–µ –Ω–∞–π–¥–µ–Ω")





class XLSTMRLModel:
    """
    –ú–æ–¥–µ–ª—å xLSTM —Å RL –¥–ª—è —Ç–æ—Ä–≥–æ–≤–ª–∏ - –¢–†–Å–•–≠–¢–ê–ü–ù–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê
    """
    def __init__(self, input_shape, memory_size=64, memory_units=128, weight_decay=1e-4, gradient_clip_norm=1.0):
        self.input_shape = input_shape
        self.memory_size = memory_size
        self.memory_units = memory_units
        # üî• –î–û–ë–ê–í–õ–ï–ù–û: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
        self.weight_decay = 5e-4
        self.gradient_clip_norm = gradient_clip_norm
        
        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –î–æ–±–∞–≤—å—Ç–µ —ç—Ç–∏ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π
        self.actor_model = self._build_actor_model()
        self.critic_model = self._build_critic_model()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–≤ —Å —É—á–µ—Ç–æ–º –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        self._configure_optimizers()
        
        # üî• –î–û–ë–ê–í–õ–ï–ù–û: –ë—É—Ñ–µ—Ä –¥–ª—è –±–∞—Ç—á–µ–≤—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        self.prediction_count = 0
        self.batch_predictions = []
        self.batch_size = 32

    def _configure_optimizers(self):
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã —Å —É—á–µ—Ç–æ–º –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç—É–ø–Ω—ã –ª–∏ GPU
            physical_devices = tf.config.list_physical_devices('GPU')
            if len(physical_devices) > 0:
                # –î–ª—è GPU –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
                self.supervised_optimizer = tf.keras.optimizers.Adam(
                    learning_rate=0.001,
                    clipnorm=self.gradient_clip_norm
                )
                self.actor_optimizer = tf.keras.optimizers.Adam(
                    learning_rate=0.0005,
                    clipnorm=self.gradient_clip_norm
                )
                self.critic_optimizer = tf.keras.optimizers.Adam(
                    learning_rate=0.001,
                    clipnorm=self.gradient_clip_norm
                )
                print("–ù–∞—Å—Ç—Ä–æ–µ–Ω—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã –¥–ª—è GPU")
            else:
                # –î–ª—è CPU –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
                self.supervised_optimizer = tf.keras.optimizers.Adam(
                    learning_rate=0.0005,
                    clipnorm=self.gradient_clip_norm
                )
                self.actor_optimizer = tf.keras.optimizers.Adam(
                    learning_rate=0.0001,
                    clipnorm=self.gradient_clip_norm
                )
                self.critic_optimizer = tf.keras.optimizers.Adam(
                    learning_rate=0.0005,
                    clipnorm=self.gradient_clip_norm
                )
                print("–ù–∞—Å—Ç—Ä–æ–µ–Ω—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã –¥–ª—è CPU")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–≤: {e}")
            # Fallback –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            self.supervised_optimizer = tf.keras.optimizers.Adam(clipnorm=self.gradient_clip_norm)
            self.actor_optimizer = tf.keras.optimizers.Adam(clipnorm=self.gradient_clip_norm)
            self.critic_optimizer = tf.keras.optimizers.Adam(clipnorm=self.gradient_clip_norm)

    def _build_actor_model(self):
        """–°–æ–∑–¥–∞–µ—Ç –º–æ–¥–µ–ª—å –∞–∫—Ç–æ—Ä–∞ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏ —Ä–∞–∑–º–µ—Ä–∞"""
        inputs = layers.Input(shape=self.input_shape)
        
        # Batch Normalization –Ω–∞ –≤—Ö–æ–¥–µ
        # print(f"DEBUG Actor Model: inputs shape={inputs.shape} (before BatchNormalization)")
        x = layers.BatchNormalization()(inputs)
        # print(f"DEBUG Actor Model: x shape={x.shape} (after BatchNormalization)")
        
        # üî• –î–û–ë–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π –≤—Ö–æ–¥–∞ (–æ—Å—Ç–∞–≤–ª—è–µ–º)
        expected_features = 14  # –±–∞–∑–æ–≤—ã–µ + –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        if self.input_shape[-1] != expected_features:
            print(f"‚ö†Ô∏è –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–∞: {self.input_shape[-1]}, –æ–∂–∏–¥–∞–ª–æ—Å—å {expected_features}")
        
        # –ü–µ—Ä–≤—ã–π —Å–ª–æ–π xLSTM —Å weight decay
        # print(f"DEBUG Actor Model: x shape={x.shape} (before first RNN)")
        x = layers.RNN(
            XLSTMMemoryCell(units=self.memory_units, memory_size=self.memory_size),
            return_sequences=True
        )(x)
        # print(f"DEBUG Actor Model: x shape={x.shape} (after first RNN)")
        
        x = layers.LayerNormalization()(x)
        x = layers.Dropout(0.4)(x)
        
        # –í—Ç–æ—Ä–æ–π —Å–ª–æ–π xLSTM (—É–º–µ–Ω—å—à–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä)
        # print(f"DEBUG Actor Model: x shape={x.shape} (before second RNN)")
        x = layers.RNN(
            XLSTMMemoryCell(units=self.memory_units//2, memory_size=self.memory_size),
            return_sequences=False
        )(x)
        # print(f"DEBUG Actor Model: x shape={x.shape} (after second RNN)")
        
        x = layers.LayerNormalization()(x)
        x = layers.Dropout(0.3)(x)
        
        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ residual connections —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π
        dense1 = layers.Dense(
            128, 
            activation='relu',
            kernel_regularizer=tf.keras.regularizers.l2(self.weight_decay)
        )(x)
        dense1 = layers.Dropout(0.3)(dense1)
        
        dense2 = layers.Dense(
            64, 
            activation='relu',
            kernel_regularizer=tf.keras.regularizers.l2(self.weight_decay)
        )(dense1)
        
        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –£–±—Ä–∞–Ω–æ –ª–∏—à–Ω–µ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–æ—Ä–º –ø–µ—Ä–µ–¥ –æ–ø–µ—Ä–∞—Ü–∏–µ–π —Å–ª–æ–∂–µ–Ω–∏—è
        # print(f"DEBUG Actor Model: x (before resize) shape={x.shape}")
        
        x_static_shape = x.shape[-1]
        if x_static_shape != 64:
            x_resized = layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l2(self.weight_decay))(x)
            # print(f"DEBUG Actor Model: x_resized shape={x_resized.shape}")
        else:
            x_resized = x
            # print(f"DEBUG Actor Model: x_resized (no change) shape={x_resized.shape}")
        
        # print(f"DEBUG Actor Model: dense2 shape={dense2.shape}")
        
        # Residual connection
        # print(f"DEBUG Actor Model: x_resized.shape={x_resized.shape}, dense2.shape={dense2.shape}") # –û—Å—Ç–∞–≤–ª—è–µ–º, –µ—Å–ª–∏ —Ö–æ—Ç–∏–º –ø—Ä–æ–≤–µ—Ä—è—Ç—å —Ñ–æ—Ä–º—ã –ø–µ—Ä–µ–¥ —Å–ª–æ–∂–µ–Ω–∏–µ–º
        if x_resized.shape[-1] != dense2.shape[-1]:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞: –§–æ—Ä–º—ã –¥–ª—è residual connection –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç: x_resized={x_resized.shape}, dense2={dense2.shape}")
        
        x = layers.Add()([x_resized, dense2])
        # print(f"DEBUG Actor Model: x (after add) shape={x.shape}")
        
        # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –≤–µ—Å–æ–≤
        outputs = layers.Dense(
            3, 
            activation='softmax',
            kernel_regularizer=tf.keras.regularizers.l2(self.weight_decay),
            kernel_constraint=tf.keras.constraints.MaxNorm(max_value=2.0) # üî• –†–ê–°–ö–û–ú–ú–ï–ù–¢–ò–†–û–í–ê–¢–¨
        )(x)
        
        model = models.Model(inputs=inputs, outputs=outputs)
        
        # üî• –î–û–ë–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–æ—Å—Ç–∞–≤–ª—è–µ–º)
        total_params = model.count_params()
        max_params = 10_000_000  # 10M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–∞–∫—Å–∏–º—É–º
        if total_params > max_params:
            print(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∞—è: {total_params:,} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–º–∞–∫—Å–∏–º—É–º: {max_params:,})")
        else:
            print(f"‚úÖ –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ Actor: {total_params:,} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
        
        return model

    def _build_critic_model(self):
        """–°–æ–∑–¥–∞–µ—Ç –º–æ–¥–µ–ª—å –∫—Ä–∏—Ç–∏–∫–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –¥–µ–π—Å—Ç–≤–∏–π"""
        inputs = layers.Input(shape=self.input_shape)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        # print(f"DEBUG Critic Model: inputs shape={inputs.shape} (before LayerNormalization)")
        x = layers.LayerNormalization()(inputs)
        # print(f"DEBUG Critic Model: x shape={x.shape} (after LayerNormalization)")
        
        # –ü–µ—Ä–≤—ã–π —Å–ª–æ–π xLSTM
        # print(f"DEBUG Critic Model: x shape={x.shape} (before first RNN)")
        x = layers.RNN(XLSTMMemoryCell(units=self.memory_units,
                                       memory_size=self.memory_size),
                      return_sequences=True)(x)
        # print(f"DEBUG Critic Model: x shape={x.shape} (after first RNN)")
        
        x = layers.LayerNormalization()(x)
        x = layers.Dropout(0.2)(x)
        
        # –í—Ç–æ—Ä–æ–π —Å–ª–æ–π xLSTM
        # print(f"DEBUG Critic Model: x shape={x.shape} (before second RNN)")
        x = layers.RNN(XLSTMMemoryCell(units=self.memory_units,
                                       memory_size=self.memory_size),
                      return_sequences=False)(x)
        # print(f"DEBUG Critic Model: x shape={x.shape} (after second RNN)")
        
        x = layers.LayerNormalization()(x)
        x = layers.Dropout(0.2)(x)
        
        # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏ –° –†–ï–ì–£–õ–Ø–†–ò–ó–ê–¶–ò–ï–ô
        # print(f"DEBUG Critic Model: x shape={x.shape} (before first Dense)")
        x = layers.Dense(64, activation='relu',
                        kernel_regularizer=tf.keras.regularizers.l2(self.weight_decay))(x)
        # print(f"DEBUG Critic Model: x shape={x.shape} (after first Dense)")
        
        # print(f"DEBUG Critic Model: x shape={x.shape} (before second Dense)")
        x = layers.Dense(32, activation='relu',
                        kernel_regularizer=tf.keras.regularizers.l2(self.weight_decay))(x)
        # print(f"DEBUG Critic Model: x shape={x.shape} (after second Dense)")
        
        # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π –° –†–ï–ì–£–õ–Ø–†–ò–ó–ê–¶–ò–ï–ô
        # print(f"DEBUG Critic Model: x shape={x.shape} (before output Dense)")
        outputs = layers.Dense(1, 
                              kernel_regularizer=tf.keras.regularizers.l2(self.weight_decay))(x)
        # print(f"DEBUG Critic Model: outputs shape={outputs.shape} (after output Dense)")
        
        model = models.Model(inputs=inputs, outputs=outputs)
        
        # üî• –î–û–ë–ê–í–ò–¢–¨: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–æ—Å—Ç–∞–≤–ª—è–µ–º)
        total_params = model.count_params()
        max_params = 10_000_000
        if total_params > max_params:
            print(f"‚ö†Ô∏è Critic –º–æ–¥–µ–ª—å —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∞—è: {total_params:,} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
        else:
            print(f"‚úÖ –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ Critic: {total_params:,} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
        
        return model

    def compile_for_supervised_learning(self):
        """–ö–æ–º–ø–∏–ª–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è —ç—Ç–∞–ø–∞ 1: Supervised Learning"""
        # –£–±–∏—Ä–∞–µ–º precision/recall –∏–∑ compile ‚Äî –±—É–¥–µ–º —Å—á–∏—Ç–∞—Ç—å –∏—Ö –æ—Ç–¥–µ–ª—å–Ω–æ
        self.actor_model.compile(
            optimizer=self.supervised_optimizer,
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy'],
            run_eagerly=False  # –æ—Å—Ç–∞–≤–ª—è–µ–º False –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –º–æ–∂–Ω–æ –≤—Ä–µ–º–µ–Ω–Ω–æ —Å—Ç–∞–≤–∏—Ç—å True –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        )
        print("‚úÖ –ú–æ–¥–µ–ª—å —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è supervised learning (–±–µ–∑ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö precision/recall)")

    def compile_for_reward_modeling(self):
        """–ö–æ–º–ø–∏–ª–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è —ç—Ç–∞–ø–∞ 2: Reward Model Training"""
        self.critic_model.compile(
            optimizer=tf.keras.optimizers.Adam(
                learning_rate=0.001,
                clipnorm=self.gradient_clip_norm  # üî• –î–û–ë–ê–í–õ–ï–ù–û: Gradient clipping
            ),
            loss='mse',
            metrics=['mae']
        )
        print("‚úÖ –ú–æ–¥–µ–ª—å —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è reward modeling")

    def save(self, path='models', stage=""):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–µ–ª—å —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —ç—Ç–∞–ø–∞"""
        if not os.path.exists(path):
            os.makedirs(path)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —ç—Ç–∞–ø–∞
        actor_name = f'xlstm_rl_actor{stage}.keras'
        critic_name = f'xlstm_rl_critic{stage}.keras'
        
        self.actor_model.save(os.path.join(path, actor_name))
        self.critic_model.save(os.path.join(path, critic_name))
        
        print(f"–ú–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {path} (—ç—Ç–∞–ø: {stage})")

    def load(self, path='models', stage=""):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —ç—Ç–∞–ø–∞"""
        actor_name = f'xlstm_rl_actor{stage}.keras'
        critic_name = f'xlstm_rl_critic{stage}.keras'
        
        actor_path = os.path.join(path, actor_name)
        critic_path = os.path.join(path, critic_name)
        
        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π
        try:
            if os.path.exists(actor_path) and os.path.exists(critic_path):
                self.actor_model = tf.keras.models.load_model(
                    actor_path, 
                    custom_objects={'XLSTMMemoryCell': XLSTMMemoryCell}
                )
                self.critic_model = tf.keras.models.load_model(
                    critic_path,
                    custom_objects={'XLSTMMemoryCell': XLSTMMemoryCell}
                )
                print(f"–ú–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã (—ç—Ç–∞–ø: {stage})")
            else:
                print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —ç—Ç–∞–ø–∞: {stage}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–µ–π: {e}")
            return False

    def predict_action(self, state):
        """–ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –¥–µ–π—Å—Ç–≤–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
        if len(state.shape) == 2:
            state = np.expand_dims(state, axis=0)
        
        if state.dtype != np.float32:
            state = state.astype(np.float32)
        
        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º predict_on_batch –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        try:
            action_probs = self.actor_model.predict_on_batch(state)[0]
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –≤ predict_on_batch, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback: {e}")
            action_probs = self.actor_model.predict(state, verbose=0)[0]
        
        # üî• –î–û–ë–ê–í–õ–ï–ù–û: –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
        self.prediction_count += 1
        if self.prediction_count % 50 == 0:  # –£–≤–µ–ª–∏—á–µ–Ω–∞ —á–∞—Å—Ç–æ—Ç–∞ –æ—á–∏—Å—Ç–∫–∏
            gc.collect()
            if self.prediction_count % 500 == 0:  # –ì–ª—É–±–æ–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –∫–∞–∂–¥—ã–µ 500 –≤—ã–∑–æ–≤–æ–≤
                tf.keras.backend.clear_session()
                print(f"–ì–ª—É–±–æ–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –ø–æ—Å–ª–µ {self.prediction_count} –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
        
        return action_probs
    
    def predict_value(self, state):
        """–ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
        if len(state.shape) == 2:
            state = np.expand_dims(state, axis=0)
        
        if state.dtype != np.float32:
            state = state.astype(np.float32)
        
        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º predict_on_batch
        try:
            value = self.critic_model.predict_on_batch(state)[0]
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –≤ predict_on_batch –¥–ª—è critic: {e}")
            value = self.critic_model.predict(state, verbose=0)[0]
        
        # –ê–Ω–∞–ª–æ–≥–∏—á–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
        self.prediction_count += 1
        if self.prediction_count % 50 == 0:
            gc.collect()
            if self.prediction_count % 500 == 0:
                tf.keras.backend.clear_session()
        
        return value
    
    def predict_batch_actions(self, states):
        """üî• –î–û–ë–ê–í–õ–ï–ù–û: –ë–∞—Ç—á–µ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π"""
        if len(states) == 0:
            return np.array([])
        
        states = np.array(states, dtype=np.float32)
        if len(states.shape) == 2:
            states = np.expand_dims(states, axis=1)
        
        action_probs = self.actor_model.predict_on_batch(states)
        
        # –û—á–∏—Å—Ç–∫–∞ –ø–æ—Å–ª–µ –±–∞—Ç—á–µ–≤–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        gc.collect()
        
        return action_probs