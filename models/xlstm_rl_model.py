import tensorflow as tf
from tensorflow.keras import layers, models
import numpy as np
import os
import tensorflow.keras.backend as K
import gc
import config

# –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –∏–º–ø–æ—Ä—Ç
try:
    from models.xlstm_memory_cell import XLSTMMemoryCell
except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ XLSTMMemoryCell: {e}")
    print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª models/xlstm_memory_cell.py —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
    raise ImportError("XLSTMMemoryCell –Ω–µ –Ω–∞–π–¥–µ–Ω")


class FocalLoss(tf.keras.losses.Loss):
    """
    –ê—Å—Å–∏–º–µ—Ç—Ä–∏—á–Ω–∞—è Focal Loss —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π per-class alpha/gamma,
    Class-Conditional Label Smoothing –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º —à—Ç—Ä–∞—Ñ–æ–º –∑–∞
    —Å–≤–µ—Ä—Ö-—É–≤–µ—Ä–µ–Ω–Ω—ã–µ BUY (entropy penalty).
    """
    def __init__(self,
                 alpha=0.25,
                 gamma=2.0,
                 label_smoothing=0.1,
                 per_class_alpha=None,   # [Œ±_SELL, Œ±_HOLD, Œ±_BUY]
                 per_class_gamma=None,   # [Œ≥_SELL, Œ≥_HOLD, Œ≥_BUY]
                 per_class_smoothing=None,  # [s_SELL, s_HOLD, s_BUY]
                 entropy_penalty_lambda=0.0,  # Œª for BUY confidence penalty
                 **kwargs):
        super().__init__(**kwargs)
        self.alpha = alpha
        self.gamma = gamma
        self.label_smoothing = label_smoothing
        self.per_class_alpha = per_class_alpha
        self.per_class_gamma = per_class_gamma
        self.per_class_smoothing = per_class_smoothing
        self.entropy_penalty_lambda = entropy_penalty_lambda
    
    def call(self, y_true, y_pred):
        # Ensure y_true is rank-1 (sparse labels)
        y_true = tf.cast(tf.reshape(y_true, [-1]), tf.int32)
        num_classes = tf.shape(y_pred)[-1]
        num_classes_f = tf.cast(num_classes, tf.float32)
        
        # One-hot and per-class label smoothing
        y_true_onehot = tf.one_hot(y_true, depth=num_classes, dtype=tf.float32)
        if self.per_class_smoothing is not None:
            smoothing_vec = tf.gather(tf.constant(self.per_class_smoothing, dtype=tf.float32), y_true)
        else:
            smoothing_vec = tf.fill(tf.shape(y_true), tf.cast(self.label_smoothing, tf.float32))
        smoothing_vec = tf.expand_dims(smoothing_vec, axis=-1)
        y_true_smooth = y_true_onehot * (1.0 - smoothing_vec) + smoothing_vec / num_classes_f
        
        # Cross-entropy with smoothed labels
        y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0 - 1e-7)
        ce_loss = -tf.reduce_sum(y_true_smooth * tf.math.log(y_pred), axis=-1)
        
        # p_t: probability assigned to the true class
        p_t = tf.reduce_sum(y_true_onehot * y_pred, axis=-1)
        
        # Per-class alpha and gamma
        if self.per_class_alpha is not None:
            alpha_t = tf.gather(tf.constant(self.per_class_alpha, dtype=tf.float32), y_true)
        else:
            alpha_t = tf.fill(tf.shape(y_true), tf.cast(self.alpha, tf.float32))
        
        if self.per_class_gamma is not None:
            gamma_t = tf.gather(tf.constant(self.per_class_gamma, dtype=tf.float32), y_true)
        else:
            gamma_t = tf.fill(tf.shape(y_true), tf.cast(self.gamma, tf.float32))
        
        focal_factor = tf.pow(1.0 - p_t, gamma_t)
        focal_loss = alpha_t * focal_factor * ce_loss
        
        # üî• –£–õ–£–ß–®–ï–ù–û: Entropy penalty –¥–ª—è –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤ —Å –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
        if self.entropy_penalty_lambda > 0.0:
            entropy = -tf.reduce_sum(y_pred * tf.math.log(y_pred), axis=-1)
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —à—Ç—Ä–∞—Ñ –∫ –ª—é–±–æ–º—É –∫–ª–∞—Å—Å—É —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é > 0.8
            max_pred = tf.reduce_max(y_pred, axis=-1)
            high_confidence = tf.cast(tf.greater(max_pred, 0.8), tf.float32)
            penalty = self.entropy_penalty_lambda * (1.0 - entropy) * high_confidence
            focal_loss = focal_loss + penalty
        
        return focal_loss
    
    def get_config(self):
        config = super().get_config()
        config.update({
            'alpha': self.alpha,
            'gamma': self.gamma,
            'label_smoothing': self.label_smoothing,
            'per_class_alpha': self.per_class_alpha,
            'per_class_gamma': self.per_class_gamma,
            'per_class_smoothing': self.per_class_smoothing,
            'entropy_penalty_lambda': self.entropy_penalty_lambda,
        })
        return config


class WarmUpCosineDecayScheduler(tf.keras.callbacks.Callback):
    """
    Learning Rate Scheduler —Å WarmUp –∏ Cosine Decay
    –£–ª—É—á—à–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –∏ –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü–∏—é. –ü–∏–∫ –±–µ—Ä—ë–º –∏–∑ config.LR_BASE.
    """
    def __init__(self, warmup_epochs=2, total_epochs=50, base_lr=None, min_lr=1e-6):
        super().__init__()
        self.warmup_epochs = warmup_epochs
        self.total_epochs = total_epochs
        # Base LR –º–æ–∂–µ—Ç –ø—Ä–∏—Ö–æ–¥–∏—Ç—å –∏–∑–≤–Ω–µ, –∏–Ω–∞—á–µ –∏–∑ config
        self.base_lr = base_lr if base_lr is not None else getattr(config, 'LR_BASE', 6e-4)
        self.min_lr = min_lr
        
    def on_epoch_begin(self, epoch, logs=None):
        if epoch < self.warmup_epochs:
            # WarmUp phase: –ª–∏–Ω–µ–π–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ LR
            lr = self.base_lr * (epoch + 1) / max(1, self.warmup_epochs)
        else:
            # Cosine Decay phase
            progress = (epoch - self.warmup_epochs) / max(1, (self.total_epochs - self.warmup_epochs))
            progress = np.clip(progress, 0.0, 1.0)
            lr = self.min_lr + (self.base_lr - self.min_lr) * 0.5 * (1 + np.cos(np.pi * progress))
        
        try:
            self.model.optimizer.learning_rate.assign(lr)
            print(f"Epoch {epoch + 1}: –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è: {lr:.6f}")
        except Exception as e:
            print(f"[LR SCHED] skip assign: {e}")





class EMAWeightsCallback(tf.keras.callbacks.Callback):
    """–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –≤–µ—Å–æ–≤. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤–∞–ª–∏–¥–∞—Ü–∏—é –Ω–∞ EMA-–≤–µ—Å–∞—Ö.
    - –û–±–Ω–æ–≤–ª—è–µ—Ç EMA –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –±–∞—Ç—á–∞
    - –ù–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–æ–∂–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ –ø–æ–¥–º–µ–Ω—è—Ç—å –≤–µ—Å–∞ –Ω–∞ EMA –∏ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –æ–±—Ä–∞—Ç–Ω–æ
    """
    def __init__(self, decay=None, use_for_validation=None):
        super().__init__()
        self.decay = float(decay if decay is not None else getattr(config, 'EMA_DECAY', 0.999))
        self.use_for_validation = bool(use_for_validation if use_for_validation is not None else getattr(config, 'USE_EMA_VALIDATION', True))
        self.ema_weights = None
        self.train_weights = None
    
    def on_train_begin(self, logs=None):
        # model.get_weights() —É–∂–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç numpy arrays, –Ω–µ –Ω—É–∂–Ω–æ –≤—ã–∑—ã–≤–∞—Ç—å .numpy()
        weights = self.model.get_weights()
        self.ema_weights = [w.copy() if hasattr(w, 'copy') else np.array(w).copy() for w in weights]
    
    def on_train_batch_end(self, batch, logs=None):
        current = self.model.get_weights()
        for i in range(len(self.ema_weights)):
            self.ema_weights[i] = self.decay * self.ema_weights[i] + (1.0 - self.decay) * current[i]
    
    def on_test_begin(self, logs=None):
        if not self.use_for_validation:
            return
        try:
            self.train_weights = self.model.get_weights()
            self.model.set_weights(self.ema_weights)
        except Exception as e:
            print(f"[EMA] skip swap to EMA on validation begin: {e}")
    
    def on_test_end(self, logs=None):
        if not self.use_for_validation:
            return
        try:
            if self.train_weights is not None:
                self.model.set_weights(self.train_weights)
                self.train_weights = None
        except Exception as e:
            print(f"[EMA] skip restore train weights after validation: {e}")


class XLSTMRLModel:
    """
    –ú–æ–¥–µ–ª—å xLSTM —Å RL –¥–ª—è —Ç–æ—Ä–≥–æ–≤–ª–∏ - –¢–†–Å–•–≠–¢–ê–ü–ù–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê
    """
    def __init__(self, input_shape, memory_size=64, memory_units=128, weight_decay=1e-4, gradient_clip_norm=1.0):
        self.input_shape = input_shape
        self.memory_size = memory_size
        self.memory_units = memory_units
        # üî• –î–û–ë–ê–í–õ–ï–ù–û: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ (–ø–æ–¥–∫–ª—é—á–µ–Ω—ã –∫ config)
        self.weight_decay = float(getattr(config, 'WEIGHT_DECAY_L2', weight_decay))
        self.dropout_rnn1 = float(getattr(config, 'DROPOUT_RNN1', 0.6))
        self.dropout_rnn2 = float(getattr(config, 'DROPOUT_RNN2', 0.5))
        self.gradient_clip_norm = gradient_clip_norm
        
        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –î–æ–±–∞–≤—å—Ç–µ —ç—Ç–∏ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π
        self.actor_model = self._build_actor_model()
        self.critic_model = self._build_critic_model()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è bias –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–ª–æ—è –ø–æ–¥ —Ü–µ–ª–µ–≤—ã–µ –¥–æ–ª–∏ (SELL,HOLD,BUY)
        try:
            priors = np.array(getattr(config, 'TARGET_CLASS_RATIOS', [0.33, 0.40, 0.33]), dtype=np.float32)
            logits_bias = np.log(np.clip(priors, 1e-8, 1.0))
            last_dense = self.actor_model.get_layer('classifier')
            # –ï—Å–ª–∏ softmax, —Å–¥–≤–∏–≥ bias –¥–æ–ø—É—Å—Ç–∏–º
            last_dense.bias.assign(logits_bias)
            print(f"[INIT] classifier bias set to log-priors: {priors}")
        except Exception as e:
            print(f"[INIT] skip classifier bias init: {e}")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–≤ —Å —É—á–µ—Ç–æ–º –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        self._configure_optimizers()
        
        # üî• –î–û–ë–ê–í–õ–ï–ù–û: –ë—É—Ñ–µ—Ä –¥–ª—è –±–∞—Ç—á–µ–≤—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        self.prediction_count = 0
        self.batch_predictions = []
        self.batch_size = 32

    def _configure_optimizers(self):
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã —Å —É—á–µ—Ç–æ–º –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç—É–ø–Ω—ã –ª–∏ GPU
            physical_devices = tf.config.list_physical_devices('GPU')
            if len(physical_devices) > 0:
                # –î–ª—è GPU –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
                self.supervised_optimizer = tf.keras.optimizers.Adam(
                    clipnorm=self.gradient_clip_norm
                )
                # Use configurable base LR for supervised phase (stabilize early training)
                self.supervised_optimizer.learning_rate = tf.Variable(getattr(config, 'LR_BASE', 6e-4))
                self.actor_optimizer = tf.keras.optimizers.Adam(
                    clipnorm=self.gradient_clip_norm
                )
                self.actor_optimizer.learning_rate = tf.Variable(0.0005)
                self.critic_optimizer = tf.keras.optimizers.Adam(
                    clipnorm=self.gradient_clip_norm
                )
                self.critic_optimizer.learning_rate = tf.Variable(0.001)
                print("–ù–∞—Å—Ç—Ä–æ–µ–Ω—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã –¥–ª—è GPU")
            else:
                # –î–ª—è CPU –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
                self.supervised_optimizer = tf.keras.optimizers.Adam(
                    clipnorm=self.gradient_clip_norm
                )
                # Use configurable base LR for CPU as well
                self.supervised_optimizer.learning_rate = tf.Variable(getattr(config, 'LR_BASE', 6e-4))
                self.actor_optimizer = tf.keras.optimizers.Adam(
                    clipnorm=self.gradient_clip_norm
                )
                self.actor_optimizer.learning_rate = tf.Variable(0.0001)
                self.critic_optimizer = tf.keras.optimizers.Adam(
                    clipnorm=self.gradient_clip_norm
                )
                self.critic_optimizer.learning_rate = tf.Variable(0.0005)
                print("–ù–∞—Å—Ç—Ä–æ–µ–Ω—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã –¥–ª—è CPU")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–≤: {e}")
            # Fallback –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            self.supervised_optimizer = tf.keras.optimizers.Adam(
                clipnorm=self.gradient_clip_norm
            )
            self.supervised_optimizer.learning_rate = tf.Variable(0.001)
            self.actor_optimizer = tf.keras.optimizers.Adam(
                clipnorm=self.gradient_clip_norm
            )
            self.actor_optimizer.learning_rate = tf.Variable(0.001)
            self.critic_optimizer = tf.keras.optimizers.Adam(
                clipnorm=self.gradient_clip_norm
            )
            self.critic_optimizer.learning_rate = tf.Variable(0.001)

    def _build_actor_model(self):
        """–°–æ–∑–¥–∞–µ—Ç –º–æ–¥–µ–ª—å –∞–∫—Ç–æ—Ä–∞ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏ —Ä–∞–∑–º–µ—Ä–∞"""
        inputs = layers.Input(shape=self.input_shape)
        
        # Batch Normalization –Ω–∞ –≤—Ö–æ–¥–µ
        # print(f"DEBUG Actor Model: inputs shape={inputs.shape} (before BatchNormalization)")
        x = layers.BatchNormalization()(inputs)
        # print(f"DEBUG Actor Model: x shape={x.shape} (after BatchNormalization)")
        
        # üî• –û–ë–ù–û–í–õ–ï–ù–û: –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –±–µ–∑ –∂—ë—Å—Ç–∫–æ–≥–æ —á–∏—Å–ª–∞ —Ñ–∏—á–µ–π
        expected_features = self.input_shape[-1]
        # print(f"[INFO] –í—Ö–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {expected_features}")
        
        # –ü–µ—Ä–≤—ã–π —Å–ª–æ–π xLSTM —Å weight decay
        # print(f"DEBUG Actor Model: x shape={x.shape} (before first RNN)")
        x = layers.RNN(
            XLSTMMemoryCell(units=self.memory_units, memory_size=self.memory_size),
            return_sequences=True
        )(x)
        # print(f"DEBUG Actor Model: x shape={x.shape} (after first RNN)")
        
        x = layers.LayerNormalization()(x)
        # Dropout after first RNN, configurable via config
        x = layers.Dropout(self.dropout_rnn1)(x)
        
        # –í—Ç–æ—Ä–æ–π —Å–ª–æ–π xLSTM (—É–º–µ–Ω—å—à–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä)
        # print(f"DEBUG Actor Model: x shape={x.shape} (before second RNN)")
        x = layers.RNN(
            XLSTMMemoryCell(units=self.memory_units//2, memory_size=self.memory_size),
            return_sequences=False
        )(x)
        # print(f"DEBUG Actor Model: x shape={x.shape} (after second RNN)")
        
        x = layers.LayerNormalization()(x)
        # Dropout after second RNN, configurable via config
        x = layers.Dropout(self.dropout_rnn2)(x)
        
        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ residual connections —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π
        dense1 = layers.Dense(
            128, 
            activation='relu',
            kernel_regularizer=tf.keras.regularizers.l2(self.weight_decay)
        )(x)
        dense1 = layers.Dropout(0.5)(dense1)
        
        dense2 = layers.Dense(
            64, 
            activation='relu',
            kernel_regularizer=tf.keras.regularizers.l2(self.weight_decay)
        )(dense1)
        
        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –£–±—Ä–∞–Ω–æ –ª–∏—à–Ω–µ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–æ—Ä–º –ø–µ—Ä–µ–¥ –æ–ø–µ—Ä–∞—Ü–∏–µ–π —Å–ª–æ–∂–µ–Ω–∏—è
        # print(f"DEBUG Actor Model: x (before resize) shape={x.shape}")
        
        x_static_shape = x.shape[-1]
        if x_static_shape != 64:
            x_resized = layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l2(self.weight_decay))(x)
            # print(f"DEBUG Actor Model: x_resized shape={x_resized.shape}")
        else:
            x_resized = x
            # print(f"DEBUG Actor Model: x_resized (no change) shape={x_resized.shape}")
        
        # print(f"DEBUG Actor Model: dense2 shape={dense2.shape}")
        
        # Residual connection
        # print(f"DEBUG Actor Model: x_resized.shape={x_resized.shape}, dense2.shape={dense2.shape}") # –û—Å—Ç–∞–≤–ª—è–µ–º, –µ—Å–ª–∏ —Ö–æ—Ç–∏–º –ø—Ä–æ–≤–µ—Ä—è—Ç—å —Ñ–æ—Ä–º—ã –ø–µ—Ä–µ–¥ —Å–ª–æ–∂–µ–Ω–∏–µ–º
        if x_resized.shape[-1] != dense2.shape[-1]:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞: –§–æ—Ä–º—ã –¥–ª—è residual connection –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç: x_resized={x_resized.shape}, dense2={dense2.shape}")
        
        x = layers.Add()([x_resized, dense2])
        # print(f"DEBUG Actor Model: x (after add) shape={x.shape}")
        
        # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –≤–µ—Å–æ–≤
        outputs = layers.Dense(
            3, 
            activation='softmax',
            kernel_regularizer=tf.keras.regularizers.l2(self.weight_decay),
            kernel_constraint=tf.keras.constraints.MaxNorm(max_value=2.0),
            name='classifier'
        )(x)
        
        model = models.Model(inputs=inputs, outputs=outputs)
        
        # üî• –î–û–ë–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–æ—Å—Ç–∞–≤–ª—è–µ–º)
        total_params = model.count_params()
        max_params = 10_000_000  # 10M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–∞–∫—Å–∏–º—É–º
        if total_params > max_params:
            print(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∞—è: {total_params:,} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–º–∞–∫—Å–∏–º—É–º: {max_params:,})")
        else:
            print(f"‚úÖ –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ Actor: {total_params:,} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
        
        return model

    def _build_critic_model(self):
        """–°–æ–∑–¥–∞–µ—Ç –º–æ–¥–µ–ª—å –∫—Ä–∏—Ç–∏–∫–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –¥–µ–π—Å—Ç–≤–∏–π"""
        inputs = layers.Input(shape=self.input_shape)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        # print(f"DEBUG Critic Model: inputs shape={inputs.shape} (before LayerNormalization)")
        x = layers.LayerNormalization()(inputs)
        # print(f"DEBUG Critic Model: x shape={x.shape} (after LayerNormalization)")
        
        # –ü–µ—Ä–≤—ã–π —Å–ª–æ–π xLSTM
        # print(f"DEBUG Critic Model: x shape={x.shape} (before first RNN)")
        x = layers.RNN(XLSTMMemoryCell(units=self.memory_units,
                                       memory_size=self.memory_size),
                      return_sequences=True)(x)
        # print(f"DEBUG Critic Model: x shape={x.shape} (after first RNN)")

        x = layers.LayerNormalization()(x)
        x = layers.Dropout(0.4)(x)
        
        # –í—Ç–æ—Ä–æ–π —Å–ª–æ–π xLSTM
        # print(f"DEBUG Critic Model: x shape={x.shape} (before second RNN)")
        x = layers.RNN(XLSTMMemoryCell(units=self.memory_units,
                                       memory_size=self.memory_size),
                      return_sequences=False)(x)
        # print(f"DEBUG Critic Model: x shape={x.shape} (after second RNN)")

        x = layers.LayerNormalization()(x)
        x = layers.Dropout(0.4)(x)
        
        # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏ –° –†–ï–ì–£–õ–Ø–†–ò–ó–ê–¶–ò–ï–ô
        # print(f"DEBUG Critic Model: x shape={x.shape} (before first Dense)")
        x = layers.Dense(64, activation='relu',
                        kernel_regularizer=tf.keras.regularizers.l2(self.weight_decay))(x)
        # print(f"DEBUG Critic Model: x shape={x.shape} (after first Dense)")
        
        # print(f"DEBUG Critic Model: x shape={x.shape} (before second Dense)")
        x = layers.Dense(32, activation='relu',
                        kernel_regularizer=tf.keras.regularizers.l2(self.weight_decay))(x)
        # print(f"DEBUG Critic Model: x shape={x.shape} (after second Dense)")
        
        # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π –° –†–ï–ì–£–õ–Ø–†–ò–ó–ê–¶–ò–ï–ô
        # print(f"DEBUG Critic Model: x shape={x.shape} (before output Dense)")
        outputs = layers.Dense(1, 
                              kernel_regularizer=tf.keras.regularizers.l2(self.weight_decay))(x)
        # print(f"DEBUG Critic Model: outputs shape={outputs.shape} (after output Dense)")
        
        model = models.Model(inputs=inputs, outputs=outputs)
        
        # üî• –î–û–ë–ê–í–ò–¢–¨: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–æ—Å—Ç–∞–≤–ª—è–µ–º)
        total_params = model.count_params()
        max_params = 10_000_000
        if total_params > max_params:
            print(f"‚ö†Ô∏è Critic –º–æ–¥–µ–ª—å —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∞—è: {total_params:,} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
        else:
            print(f"‚úÖ –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ Critic: {total_params:,} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
        
        return model

    def compile_for_supervised_learning(self):
        """–ö–æ–º–ø–∏–ª–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è —ç—Ç–∞–ø–∞ 1: Supervised Learning —Å –ø–ª–∞–≤–Ω—ã–º –ø–µ—Ä–µ—Ö–æ–¥–æ–º CE‚ÜíAFL"""
        # –≠—Ç–∞–ø 1‚ÄìN_warm: —Å–º–µ—à–∞–Ω–Ω–∞—è –ø–æ—Ç–µ—Ä—è CE –∏ AFL –¥–ª—è –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞
        warm_epochs = int(getattr(config, 'AFL_WARMUP_EPOCHS', 5))
        ce_weight_start = float(getattr(config, 'CE_WEIGHT_START', 0.8))  # –Ω–∞—á–∞–ª—å–Ω—ã–π –≤–µ—Å CE
        ce_weight_end = float(getattr(config, 'CE_WEIGHT_END', 0.0))      # –∫ –∫–æ–Ω—Ü—É warmup CE —É—Ö–æ–¥–∏—Ç
        
        # –ë–∞–∑–æ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø–æ—Ç–µ—Ä—å
        focal_loss = FocalLoss(
            per_class_alpha=getattr(config, 'AFL_ALPHA', None),
            per_class_gamma=getattr(config, 'AFL_GAMMA', None),
            per_class_smoothing=getattr(config, 'CLASS_SMOOTHING', None),
            entropy_penalty_lambda=getattr(config, 'ENTROPY_PENALTY_LAMBDA', 0.0),
            alpha=0.25,
            gamma=2.0,
            label_smoothing=0.1,
        )
        ce_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)
        
        class MixedLoss(tf.keras.losses.Loss):
            def __init__(self, **kwargs):
                super().__init__(**kwargs)
                # –°–æ–∑–¥–∞–µ–º tf.Variable –Ω–∞ —Ç–æ–º –∂–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ, —á—Ç–æ –∏ –º–æ–¥–µ–ª—å
                with tf.device('/GPU:0' if tf.config.list_physical_devices('GPU') else '/CPU:0'):
                    self.epoch_var = tf.Variable(0.0, trainable=False, dtype=tf.float32, name='mixed_loss_epoch')
                
            def set_epoch(self, epoch):
                """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ç–µ–∫—É—â—É—é —ç–ø–æ—Ö—É"""
                self.epoch_var.assign(float(epoch))
                
            def call(self, y_true, y_pred):
                # –õ–∏–Ω–µ–π–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –≤–µ—Å–∞ CE –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–µ–∫—É—â–µ–π —ç–ø–æ—Ö–∏
                if warm_epochs > 0:
                    t = tf.clip_by_value(self.epoch_var / float(warm_epochs), 0.0, 1.0)
                else:
                    t = 1.0
                ce_w = ce_weight_start * (1.0 - t) + ce_weight_end * t
                afl_w = 1.0 - ce_w
                return ce_w * ce_loss(y_true, y_pred) + afl_w * focal_loss(y_true, y_pred)
        
        mixed_loss = MixedLoss(name='mixed_ce_afl')
        
        class EpochTracker(tf.keras.callbacks.Callback):
            def on_epoch_begin(self, epoch, logs=None):
                # –ü–µ—Ä–µ–¥–∞–µ–º —Ç–µ–∫—É—â—É—é —ç–ø–æ—Ö—É –≤ –ª–æ—Å—Å, —á—Ç–æ–±—ã –æ–Ω –ø–ª–∞–≤–Ω–æ –º–µ–Ω—è–ª –≤–µ—Å–∞
                try:
                    if hasattr(self.model, 'loss') and hasattr(self.model.loss, 'set_epoch'):
                        self.model.loss.set_epoch(int(epoch))
                except Exception as e:
                    print(f"[MixedLoss] skip epoch assign: {e}")
        
        self._mixed_loss_callback = EpochTracker()
        
        self.actor_model.compile(
            optimizer=self.supervised_optimizer,
            loss=mixed_loss,
            metrics=['accuracy'],
            run_eagerly=False,
            jit_compile=True  # –í–∫–ª—é—á–∞–µ–º XLA –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        )
        print("‚úÖ –ú–æ–¥–µ–ª—å —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–∞: —Å–º–µ—à–∞–Ω–Ω–∞—è –ø–æ—Ç–µ—Ä—è CE‚ÜíAFL —Å –ª–∏–Ω–µ–π–Ω—ã–º —Å–ø–∞–¥–æ–º CE –≤ –ø–µ—Ä–≤—ã–µ —ç–ø–æ—Ö–∏")

    def compile_for_reward_modeling(self):
        """–ö–æ–º–ø–∏–ª–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è —ç—Ç–∞–ø–∞ 2: Reward Model Training"""
        optimizer = tf.keras.optimizers.Adam(
            clipnorm=self.gradient_clip_norm  # üî• –î–û–ë–ê–í–õ–ï–ù–û: Gradient clipping
        )
        optimizer.learning_rate = tf.Variable(0.001)
        self.critic_model.compile(
            optimizer=optimizer,
            loss='mse',
            metrics=['mae'],
            jit_compile=True  # –í–∫–ª—é—á–∞–µ–º XLA –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        )
        print("‚úÖ –ú–æ–¥–µ–ª—å —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è reward modeling")

    def get_training_callbacks(self, total_epochs=50, patience=10):
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–µ callbacks –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        """
        callbacks = [
            # WarmUp + Cosine Decay Learning Rate (lower peak, shorter warmup)
            WarmUpCosineDecayScheduler(
                warmup_epochs=getattr(config, 'LR_WARMUP_EPOCHS', 2),
                total_epochs=total_epochs,
                base_lr=getattr(config, 'LR_BASE', 6e-4),
                min_lr=getattr(config, 'LR_MIN', 1e-6)
            ),
            
            # EMA –≤–µ—Å–æ–≤: —Å—Ç–∞–±–∏–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞ —Å—á–µ—Ç EMA-–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            EMAWeightsCallback(
                decay=getattr(config, 'EMA_DECAY', 0.999),
                use_for_validation=getattr(config, 'USE_EMA_VALIDATION', True)
            ),

            # Early Stopping –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
            tf.keras.callbacks.EarlyStopping(
                monitor='val_loss',
                patience=patience,
                restore_best_weights=True,
                verbose=1
            ),
            
            # Model Checkpoint –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
            tf.keras.callbacks.ModelCheckpoint(
                filepath='models/best_xlstm_model.keras',
                monitor='val_loss',
                save_best_only=True,
                verbose=1
            ),
            
            # Reduce LR on Plateau (–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞—â–∏—Ç–∞)
            tf.keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=5,
                min_lr=1e-7,
                verbose=1
            )
        ]
        
        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–æ–≤ –ø–æ —ç–ø–æ—Ö–∞–º (–º—è–≥–∫–∏–π —Ä–µ–∂–∏–º)
        if getattr(config, 'DYNAMIC_CLASS_WEIGHTS', False):
            class DynamicWeightsCallback(tf.keras.callbacks.Callback):
                def __init__(self, step=0.05, target_ratios=None):
                    super().__init__()
                    self.step = step
                    self.target = np.array(target_ratios or [0.3, 0.3, 0.4])
                def on_epoch_end(self, epoch, logs=None):
                    try:
                        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
                        vd = getattr(self.model, 'validation_data', None)
                        if vd is None:
                            return
                        X_val, y_val = vd[:2]
                        preds = self.model.predict(X_val, verbose=0)
                        pred_labels = np.argmax(preds, axis=1)
                        hist = np.bincount(pred_labels, minlength=3)
                        total = max(1, len(pred_labels))
                        dist = hist / total
                        print(f"[DynWeights] pred BUY/HOLD/SELL: {dist[2]:.2%}/{dist[1]:.2%}/{dist[0]:.2%}")
                        # üî• –£–õ–£–ß–®–ï–ù–û: –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –ø—Ä–∏ —Å–∏–ª—å–Ω–æ–º –¥–∏—Å–±–∞–ª–∞–Ω—Å–µ
                        loss_obj = getattr(self.model, 'loss', None)
                        if hasattr(loss_obj, 'per_class_alpha') and loss_obj.per_class_alpha is not None:
                            alpha = np.array(loss_obj.per_class_alpha, dtype=np.float32)
                            delta = dist - self.target
                            
                            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —à–∞–≥ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏ –ø—Ä–∏ —Å–∏–ª—å–Ω–æ–º –¥–∏—Å–±–∞–ª–∞–Ω—Å–µ
                            max_deviation = np.max(np.abs(delta))
                            adaptive_step = self.step * (1.0 + 2.0 * max_deviation)  # –î–æ 3x –±–æ–ª—å—à–µ –ø—Ä–∏ —Å–∏–ª—å–Ω–æ–º –¥–∏—Å–±–∞–ª–∞–Ω—Å–µ
                            
                            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –≤–µ—Å–∞ —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º —à–∞–≥–æ–º
                            alpha[2] = float(np.clip(alpha[2] - adaptive_step * np.sign(delta[2]), 0.1, 3.0))
                            alpha[0] = float(np.clip(alpha[0] - adaptive_step * np.sign(delta[0]), 0.1, 3.0))
                            alpha[1] = float(np.clip(alpha[1] - adaptive_step * np.sign(delta[1]), 0.1, 3.0))
                            loss_obj.per_class_alpha = alpha.tolist()
                            print(f"[DynWeights] deviation={max_deviation:.3f}, step={adaptive_step:.3f}")
                            print(f"[DynWeights] per_class_alpha -> {loss_obj.per_class_alpha}")
                    except Exception as e:
                        print(f"[DynWeights] skip adjust: {e}")
            callbacks.append(DynamicWeightsCallback(
                step=getattr(config, 'DYNAMIC_WEIGHT_STEP', 0.05),
                target_ratios=getattr(config, 'TARGET_CLASS_RATIOS', [0.3, 0.3, 0.4])
            ))
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç—Ä–µ–∫–µ—Ä —ç–ø–æ—Ö –¥–ª—è —Å–º–µ—à–∞–Ω–Ω–æ–≥–æ –ª–æ—Å—Å–∞ CE‚ÜíAFL, –µ—Å–ª–∏ –æ–Ω –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –ø—Ä–∏ compile
        try:
            if hasattr(self, '_mixed_loss_callback') and self._mixed_loss_callback is not None:
                callbacks.append(self._mixed_loss_callback)
        except Exception as e:
            print(f"[Callbacks] skip adding MixedLoss epoch tracker: {e}")
        
        return callbacks

    def save(self, path='models', stage=""):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–µ–ª—å —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —ç—Ç–∞–ø–∞"""
        if not os.path.exists(path):
            os.makedirs(path)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —ç—Ç–∞–ø–∞
        actor_name = f'xlstm_rl_actor{stage}.keras'
        critic_name = f'xlstm_rl_critic{stage}.keras'
        
        self.actor_model.save(os.path.join(path, actor_name))
        self.critic_model.save(os.path.join(path, critic_name))
        
        print(f"–ú–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {path} (—ç—Ç–∞–ø: {stage})")

    def load(self, path='models', stage=""):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —ç—Ç–∞–ø–∞"""
        actor_name = f'xlstm_rl_actor{stage}.keras'
        critic_name = f'xlstm_rl_critic{stage}.keras'
        
        actor_path = os.path.join(path, actor_name)
        critic_path = os.path.join(path, critic_name)
        
        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π
        try:
            if os.path.exists(actor_path) and os.path.exists(critic_path):
                self.actor_model = tf.keras.models.load_model(
                    actor_path, 
                    custom_objects={'XLSTMMemoryCell': XLSTMMemoryCell}
                )
                self.critic_model = tf.keras.models.load_model(
                    critic_path,
                    custom_objects={'XLSTMMemoryCell': XLSTMMemoryCell}
                )
                print(f"–ú–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã (—ç—Ç–∞–ø: {stage})")
            else:
                print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —ç—Ç–∞–ø–∞: {stage}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–µ–π: {e}")
            return False

    def predict_action(self, state):
        """–ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –¥–µ–π—Å—Ç–≤–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
        if len(state.shape) == 2:
            state = np.expand_dims(state, axis=0)
        
        if state.dtype != np.float32:
            state = state.astype(np.float32)
        
        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º predict_on_batch –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        try:
            action_probs = self.actor_model.predict_on_batch(state)[0]
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –≤ predict_on_batch, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback: {e}")
            action_probs = self.actor_model.predict(state, verbose=0)[0]
        
        # üî• –î–û–ë–ê–í–õ–ï–ù–û: –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
        self.prediction_count += 1
        if self.prediction_count % 50 == 0:  # –£–≤–µ–ª–∏—á–µ–Ω–∞ —á–∞—Å—Ç–æ—Ç–∞ –æ—á–∏—Å—Ç–∫–∏
            gc.collect()
            if self.prediction_count % 500 == 0:  # –ì–ª—É–±–æ–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –∫–∞–∂–¥—ã–µ 500 –≤—ã–∑–æ–≤–æ–≤
                tf.keras.backend.clear_session()
                print(f"–ì–ª—É–±–æ–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –ø–æ—Å–ª–µ {self.prediction_count} –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
        
        return action_probs
    
    def predict_value(self, state):
        """–ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
        if len(state.shape) == 2:
            state = np.expand_dims(state, axis=0)
        
        if state.dtype != np.float32:
            state = state.astype(np.float32)
        
        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º predict_on_batch
        try:
            value = self.critic_model.predict_on_batch(state)[0]
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –≤ predict_on_batch –¥–ª—è critic: {e}")
            value = self.critic_model.predict(state, verbose=0)[0]
        
        # –ê–Ω–∞–ª–æ–≥–∏—á–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
        self.prediction_count += 1
        if self.prediction_count % 50 == 0:
            gc.collect()
            if self.prediction_count % 500 == 0:
                tf.keras.backend.clear_session()
        
        return value
    
    def predict_batch_actions(self, states):
        """üî• –î–û–ë–ê–í–õ–ï–ù–û: –ë–∞—Ç—á–µ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π"""
        if len(states) == 0:
            return np.array([])
        
        states = np.array(states, dtype=np.float32)
        if len(states.shape) == 2:
            states = np.expand_dims(states, axis=1)
        
        action_probs = self.actor_model.predict_on_batch(states)
        
        # –û—á–∏—Å—Ç–∫–∞ –ø–æ—Å–ª–µ –±–∞—Ç—á–µ–≤–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        gc.collect()
        
        return action_probs